{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "y0Zsfizj_bP0",
        "5z61hoUk43jc",
        "0l5XXZ3p8T-9",
        "ka-gtL3y88cz",
        "ag9seGa3_mw1",
        "4y067f48_rkF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiQcvKRtsROV",
        "outputId": "45194357-6bc8-435b-881d-15ec34f9aac7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (1.26.15)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TqVTjbRuxSSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592f4aa4-e8ff-4b1f-bb28-ac4df4bb51cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e12c30e4b52a>:35: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ],
      "source": [
        "from scipy.io.arff import loadarff\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import itertools\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score, precision_score, recall_score\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.layers import BatchNormalization,Dropout,Bidirectional,LSTM\n",
        "\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Convolution2D as Conv2D\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = loadarff(\"/content/ECG5000_TEST.arff\")"
      ],
      "metadata": {
        "id": "RAXsgdO-287a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(raw_data[0])"
      ],
      "metadata": {
        "id": "05aKDSY33DKp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "KfcXUsKv3GY5",
        "outputId": "5d80bbf3-f2a5-408d-f9ca-74969a9e9a35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          att1      att2      att3      att4      att5      att6      att7  \\\n",
              "0     3.690844  0.711414 -2.114091 -4.141007 -4.574472 -3.431909 -1.950791   \n",
              "1    -1.348132 -3.996038 -4.226750 -4.251187 -3.477953 -2.228422 -1.808488   \n",
              "2     1.024295 -0.590314 -1.916949 -2.806989 -3.527905 -3.638675 -2.779767   \n",
              "3     0.545657 -1.014383 -2.316698 -3.634040 -4.196857 -3.758093 -3.194444   \n",
              "4     0.661133 -1.552471 -3.124641 -4.313351 -4.017042 -3.005993 -1.832411   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "4495 -1.122969 -2.252925 -2.867628 -3.358605 -3.167849 -2.638360 -1.664162   \n",
              "4496 -0.547705 -1.889545 -2.839779 -3.457912 -3.929149 -3.966026 -3.492560   \n",
              "4497 -1.351779 -2.209006 -2.520225 -3.061475 -3.065141 -3.030739 -2.622720   \n",
              "4498 -1.124432 -1.905039 -2.192707 -2.904320 -2.900722 -2.761252 -2.569705   \n",
              "4499  0.728813  0.192597 -0.733884 -1.779456 -2.345908 -2.977565 -3.380053   \n",
              "\n",
              "          att8      att9     att10  ...    att132    att133    att134  \\\n",
              "0    -1.107067 -0.632322  0.334577  ...  0.022847  0.188937  0.480932   \n",
              "1    -1.534242 -0.779861 -0.397999  ...  1.570938  1.591394  1.549193   \n",
              "2    -2.019031 -1.980754 -1.440680  ...  0.443502  0.827582  1.237007   \n",
              "3    -2.221764 -1.588554 -1.202146  ...  0.777530  1.119240  0.902984   \n",
              "4    -1.503886 -1.071705 -0.521316  ...  1.280823  1.494315  1.618764   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "4495 -0.935655 -0.866953 -0.645363  ... -0.472419 -1.310147 -2.029521   \n",
              "4496 -2.695270 -1.849691 -1.374321  ...  1.258419  1.907530  2.280888   \n",
              "4497 -2.044092 -1.295874 -0.733839  ... -1.512234 -2.076075 -2.586042   \n",
              "4498 -2.043893 -1.490538 -0.938473  ... -2.821782 -3.268355 -3.634981   \n",
              "4499 -3.417164 -3.030925 -2.313867  ...  1.267275  1.678989  2.483389   \n",
              "\n",
              "        att135    att136    att137    att138    att139    att140  target  \n",
              "0     0.629250  0.577291  0.665527  1.035997  1.492287 -1.905073    b'1'  \n",
              "1     1.193077  0.515134  0.126274  0.267532  1.071148 -1.164009    b'1'  \n",
              "2     1.235121  1.738103  1.800767  1.816301  1.473963  1.389767    b'1'  \n",
              "3     0.554098  0.497053  0.418116  0.703108  1.064602 -0.044853    b'1'  \n",
              "4     1.447449  1.238577  1.749692  1.986803  1.422756 -0.357784    b'1'  \n",
              "...        ...       ...       ...       ...       ...       ...     ...  \n",
              "4495 -3.221294 -4.176790 -4.009720 -2.874136 -2.008369 -1.808334    b'4'  \n",
              "4496  1.895242  1.437702  1.193433  1.261335  1.150449  0.804932    b'2'  \n",
              "4497 -3.322799 -3.627311 -3.437038 -2.260023 -1.577823 -0.684531    b'2'  \n",
              "4498 -3.168765 -2.245878 -1.262260 -0.443307 -0.559769  0.108568    b'2'  \n",
              "4499  2.569073  2.122891  1.753963  1.538975  1.713781  1.309382    b'2'  \n",
              "\n",
              "[4500 rows x 141 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-854fef70-2937-470e-a87f-d1ce0fe28cf6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>att1</th>\n",
              "      <th>att2</th>\n",
              "      <th>att3</th>\n",
              "      <th>att4</th>\n",
              "      <th>att5</th>\n",
              "      <th>att6</th>\n",
              "      <th>att7</th>\n",
              "      <th>att8</th>\n",
              "      <th>att9</th>\n",
              "      <th>att10</th>\n",
              "      <th>...</th>\n",
              "      <th>att132</th>\n",
              "      <th>att133</th>\n",
              "      <th>att134</th>\n",
              "      <th>att135</th>\n",
              "      <th>att136</th>\n",
              "      <th>att137</th>\n",
              "      <th>att138</th>\n",
              "      <th>att139</th>\n",
              "      <th>att140</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.690844</td>\n",
              "      <td>0.711414</td>\n",
              "      <td>-2.114091</td>\n",
              "      <td>-4.141007</td>\n",
              "      <td>-4.574472</td>\n",
              "      <td>-3.431909</td>\n",
              "      <td>-1.950791</td>\n",
              "      <td>-1.107067</td>\n",
              "      <td>-0.632322</td>\n",
              "      <td>0.334577</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022847</td>\n",
              "      <td>0.188937</td>\n",
              "      <td>0.480932</td>\n",
              "      <td>0.629250</td>\n",
              "      <td>0.577291</td>\n",
              "      <td>0.665527</td>\n",
              "      <td>1.035997</td>\n",
              "      <td>1.492287</td>\n",
              "      <td>-1.905073</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.348132</td>\n",
              "      <td>-3.996038</td>\n",
              "      <td>-4.226750</td>\n",
              "      <td>-4.251187</td>\n",
              "      <td>-3.477953</td>\n",
              "      <td>-2.228422</td>\n",
              "      <td>-1.808488</td>\n",
              "      <td>-1.534242</td>\n",
              "      <td>-0.779861</td>\n",
              "      <td>-0.397999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.570938</td>\n",
              "      <td>1.591394</td>\n",
              "      <td>1.549193</td>\n",
              "      <td>1.193077</td>\n",
              "      <td>0.515134</td>\n",
              "      <td>0.126274</td>\n",
              "      <td>0.267532</td>\n",
              "      <td>1.071148</td>\n",
              "      <td>-1.164009</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.024295</td>\n",
              "      <td>-0.590314</td>\n",
              "      <td>-1.916949</td>\n",
              "      <td>-2.806989</td>\n",
              "      <td>-3.527905</td>\n",
              "      <td>-3.638675</td>\n",
              "      <td>-2.779767</td>\n",
              "      <td>-2.019031</td>\n",
              "      <td>-1.980754</td>\n",
              "      <td>-1.440680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.443502</td>\n",
              "      <td>0.827582</td>\n",
              "      <td>1.237007</td>\n",
              "      <td>1.235121</td>\n",
              "      <td>1.738103</td>\n",
              "      <td>1.800767</td>\n",
              "      <td>1.816301</td>\n",
              "      <td>1.473963</td>\n",
              "      <td>1.389767</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.545657</td>\n",
              "      <td>-1.014383</td>\n",
              "      <td>-2.316698</td>\n",
              "      <td>-3.634040</td>\n",
              "      <td>-4.196857</td>\n",
              "      <td>-3.758093</td>\n",
              "      <td>-3.194444</td>\n",
              "      <td>-2.221764</td>\n",
              "      <td>-1.588554</td>\n",
              "      <td>-1.202146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777530</td>\n",
              "      <td>1.119240</td>\n",
              "      <td>0.902984</td>\n",
              "      <td>0.554098</td>\n",
              "      <td>0.497053</td>\n",
              "      <td>0.418116</td>\n",
              "      <td>0.703108</td>\n",
              "      <td>1.064602</td>\n",
              "      <td>-0.044853</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.661133</td>\n",
              "      <td>-1.552471</td>\n",
              "      <td>-3.124641</td>\n",
              "      <td>-4.313351</td>\n",
              "      <td>-4.017042</td>\n",
              "      <td>-3.005993</td>\n",
              "      <td>-1.832411</td>\n",
              "      <td>-1.503886</td>\n",
              "      <td>-1.071705</td>\n",
              "      <td>-0.521316</td>\n",
              "      <td>...</td>\n",
              "      <td>1.280823</td>\n",
              "      <td>1.494315</td>\n",
              "      <td>1.618764</td>\n",
              "      <td>1.447449</td>\n",
              "      <td>1.238577</td>\n",
              "      <td>1.749692</td>\n",
              "      <td>1.986803</td>\n",
              "      <td>1.422756</td>\n",
              "      <td>-0.357784</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4495</th>\n",
              "      <td>-1.122969</td>\n",
              "      <td>-2.252925</td>\n",
              "      <td>-2.867628</td>\n",
              "      <td>-3.358605</td>\n",
              "      <td>-3.167849</td>\n",
              "      <td>-2.638360</td>\n",
              "      <td>-1.664162</td>\n",
              "      <td>-0.935655</td>\n",
              "      <td>-0.866953</td>\n",
              "      <td>-0.645363</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.472419</td>\n",
              "      <td>-1.310147</td>\n",
              "      <td>-2.029521</td>\n",
              "      <td>-3.221294</td>\n",
              "      <td>-4.176790</td>\n",
              "      <td>-4.009720</td>\n",
              "      <td>-2.874136</td>\n",
              "      <td>-2.008369</td>\n",
              "      <td>-1.808334</td>\n",
              "      <td>b'4'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4496</th>\n",
              "      <td>-0.547705</td>\n",
              "      <td>-1.889545</td>\n",
              "      <td>-2.839779</td>\n",
              "      <td>-3.457912</td>\n",
              "      <td>-3.929149</td>\n",
              "      <td>-3.966026</td>\n",
              "      <td>-3.492560</td>\n",
              "      <td>-2.695270</td>\n",
              "      <td>-1.849691</td>\n",
              "      <td>-1.374321</td>\n",
              "      <td>...</td>\n",
              "      <td>1.258419</td>\n",
              "      <td>1.907530</td>\n",
              "      <td>2.280888</td>\n",
              "      <td>1.895242</td>\n",
              "      <td>1.437702</td>\n",
              "      <td>1.193433</td>\n",
              "      <td>1.261335</td>\n",
              "      <td>1.150449</td>\n",
              "      <td>0.804932</td>\n",
              "      <td>b'2'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4497</th>\n",
              "      <td>-1.351779</td>\n",
              "      <td>-2.209006</td>\n",
              "      <td>-2.520225</td>\n",
              "      <td>-3.061475</td>\n",
              "      <td>-3.065141</td>\n",
              "      <td>-3.030739</td>\n",
              "      <td>-2.622720</td>\n",
              "      <td>-2.044092</td>\n",
              "      <td>-1.295874</td>\n",
              "      <td>-0.733839</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.512234</td>\n",
              "      <td>-2.076075</td>\n",
              "      <td>-2.586042</td>\n",
              "      <td>-3.322799</td>\n",
              "      <td>-3.627311</td>\n",
              "      <td>-3.437038</td>\n",
              "      <td>-2.260023</td>\n",
              "      <td>-1.577823</td>\n",
              "      <td>-0.684531</td>\n",
              "      <td>b'2'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4498</th>\n",
              "      <td>-1.124432</td>\n",
              "      <td>-1.905039</td>\n",
              "      <td>-2.192707</td>\n",
              "      <td>-2.904320</td>\n",
              "      <td>-2.900722</td>\n",
              "      <td>-2.761252</td>\n",
              "      <td>-2.569705</td>\n",
              "      <td>-2.043893</td>\n",
              "      <td>-1.490538</td>\n",
              "      <td>-0.938473</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.821782</td>\n",
              "      <td>-3.268355</td>\n",
              "      <td>-3.634981</td>\n",
              "      <td>-3.168765</td>\n",
              "      <td>-2.245878</td>\n",
              "      <td>-1.262260</td>\n",
              "      <td>-0.443307</td>\n",
              "      <td>-0.559769</td>\n",
              "      <td>0.108568</td>\n",
              "      <td>b'2'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4499</th>\n",
              "      <td>0.728813</td>\n",
              "      <td>0.192597</td>\n",
              "      <td>-0.733884</td>\n",
              "      <td>-1.779456</td>\n",
              "      <td>-2.345908</td>\n",
              "      <td>-2.977565</td>\n",
              "      <td>-3.380053</td>\n",
              "      <td>-3.417164</td>\n",
              "      <td>-3.030925</td>\n",
              "      <td>-2.313867</td>\n",
              "      <td>...</td>\n",
              "      <td>1.267275</td>\n",
              "      <td>1.678989</td>\n",
              "      <td>2.483389</td>\n",
              "      <td>2.569073</td>\n",
              "      <td>2.122891</td>\n",
              "      <td>1.753963</td>\n",
              "      <td>1.538975</td>\n",
              "      <td>1.713781</td>\n",
              "      <td>1.309382</td>\n",
              "      <td>b'2'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4500 rows × 141 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-854fef70-2937-470e-a87f-d1ce0fe28cf6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-854fef70-2937-470e-a87f-d1ce0fe28cf6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-854fef70-2937-470e-a87f-d1ce0fe28cf6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = loadarff(\"/content/ECG5000_TRAIN.arff\")\n",
        "df2 = pd.DataFrame(raw_data[0])\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "dz4MTQJK3Gb5",
        "outputId": "65500662-44d1-4ab7-9b1d-f5d59a0b5ede"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "0   -0.112522 -2.827204 -3.773897 -4.349751 -4.376041 -3.474986 -2.181408   \n",
              "1   -1.100878 -3.996840 -4.285843 -4.506579 -4.022377 -3.234368 -1.566126   \n",
              "2   -0.567088 -2.593450 -3.874230 -4.584095 -4.187449 -3.151462 -1.742940   \n",
              "3    0.490473 -1.914407 -3.616364 -4.318823 -4.268016 -3.881110 -2.993280   \n",
              "4    0.800232 -0.874252 -2.384761 -3.973292 -4.338224 -3.802422 -2.534510   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "495 -0.478577 -1.779959 -2.398159 -3.170112 -3.559732 -3.573956 -2.989770   \n",
              "496 -1.325210 -2.480992 -2.965356 -3.342392 -3.176351 -2.891528 -2.369679   \n",
              "497 -0.021964 -0.912434 -1.903353 -2.662829 -3.122156 -3.451490 -3.392982   \n",
              "498  0.288011 -1.098020 -2.500250 -3.598599 -3.650608 -3.281587 -2.231601   \n",
              "499 -1.133674 -2.702941 -3.120979 -3.558669 -3.312442 -2.607641 -1.354939   \n",
              "\n",
              "         att8      att9     att10  ...    att132    att133    att134  \\\n",
              "0   -1.818286 -1.250522 -0.477492  ...  0.792168  0.933541  0.796958   \n",
              "1   -0.992258 -0.754680  0.042321  ...  0.538356  0.656881  0.787490   \n",
              "2   -1.490659 -1.183580 -0.394229  ...  0.886073  0.531452  0.311377   \n",
              "3   -1.671131 -1.333884 -0.965629  ...  0.350816  0.499111  0.600345   \n",
              "4   -1.783423 -1.594450 -0.753199  ...  1.148884  0.958434  1.059025   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "495 -2.270605 -1.688277 -1.359872  ...  1.160885  1.456331  2.209421   \n",
              "496 -1.598750 -1.071751 -0.891843  ... -0.172154 -0.864803 -1.549854   \n",
              "497 -2.929937 -2.256294 -1.690706  ...  1.339479  1.457995  2.128078   \n",
              "498 -1.250656 -1.072574 -0.434310  ... -0.029242  0.071414  0.118161   \n",
              "499 -1.014740 -0.796023 -0.259599  ... -3.206942 -2.941677 -2.557140   \n",
              "\n",
              "       att135    att136    att137    att138    att139    att140  target  \n",
              "0    0.578621  0.257740  0.228077  0.123431  0.925286  0.193137    b'1'  \n",
              "1    0.724046  0.555784  0.476333  0.773820  1.119621 -1.436250    b'1'  \n",
              "2   -0.021919 -0.713683 -0.532197  0.321097  0.904227 -0.421797    b'1'  \n",
              "3    0.842069  0.952074  0.990133  1.086798  1.403011 -0.383564    b'1'  \n",
              "4    1.371682  1.277392  0.960304  0.971020  1.614392  1.421456    b'1'  \n",
              "..        ...       ...       ...       ...       ...       ...     ...  \n",
              "495  2.507175  2.198534  1.705849  1.492642  1.561890  1.520161    b'4'  \n",
              "496 -2.460243 -3.366562 -3.466546 -2.718380 -1.855209 -1.539958    b'4'  \n",
              "497  2.630759  2.295748  1.764967  1.444280  1.432347  1.457028    b'4'  \n",
              "498 -0.071967 -0.171214  0.131211  0.049872  0.010915 -0.081534    b'5'  \n",
              "499 -1.487946 -1.118880 -0.737113 -0.110840  0.001858 -0.122639    b'5'  \n",
              "\n",
              "[500 rows x 141 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ae52f07-5658-464c-8a90-ffac5c4b0bf0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>att1</th>\n",
              "      <th>att2</th>\n",
              "      <th>att3</th>\n",
              "      <th>att4</th>\n",
              "      <th>att5</th>\n",
              "      <th>att6</th>\n",
              "      <th>att7</th>\n",
              "      <th>att8</th>\n",
              "      <th>att9</th>\n",
              "      <th>att10</th>\n",
              "      <th>...</th>\n",
              "      <th>att132</th>\n",
              "      <th>att133</th>\n",
              "      <th>att134</th>\n",
              "      <th>att135</th>\n",
              "      <th>att136</th>\n",
              "      <th>att137</th>\n",
              "      <th>att138</th>\n",
              "      <th>att139</th>\n",
              "      <th>att140</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.112522</td>\n",
              "      <td>-2.827204</td>\n",
              "      <td>-3.773897</td>\n",
              "      <td>-4.349751</td>\n",
              "      <td>-4.376041</td>\n",
              "      <td>-3.474986</td>\n",
              "      <td>-2.181408</td>\n",
              "      <td>-1.818286</td>\n",
              "      <td>-1.250522</td>\n",
              "      <td>-0.477492</td>\n",
              "      <td>...</td>\n",
              "      <td>0.792168</td>\n",
              "      <td>0.933541</td>\n",
              "      <td>0.796958</td>\n",
              "      <td>0.578621</td>\n",
              "      <td>0.257740</td>\n",
              "      <td>0.228077</td>\n",
              "      <td>0.123431</td>\n",
              "      <td>0.925286</td>\n",
              "      <td>0.193137</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.100878</td>\n",
              "      <td>-3.996840</td>\n",
              "      <td>-4.285843</td>\n",
              "      <td>-4.506579</td>\n",
              "      <td>-4.022377</td>\n",
              "      <td>-3.234368</td>\n",
              "      <td>-1.566126</td>\n",
              "      <td>-0.992258</td>\n",
              "      <td>-0.754680</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.538356</td>\n",
              "      <td>0.656881</td>\n",
              "      <td>0.787490</td>\n",
              "      <td>0.724046</td>\n",
              "      <td>0.555784</td>\n",
              "      <td>0.476333</td>\n",
              "      <td>0.773820</td>\n",
              "      <td>1.119621</td>\n",
              "      <td>-1.436250</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.567088</td>\n",
              "      <td>-2.593450</td>\n",
              "      <td>-3.874230</td>\n",
              "      <td>-4.584095</td>\n",
              "      <td>-4.187449</td>\n",
              "      <td>-3.151462</td>\n",
              "      <td>-1.742940</td>\n",
              "      <td>-1.490659</td>\n",
              "      <td>-1.183580</td>\n",
              "      <td>-0.394229</td>\n",
              "      <td>...</td>\n",
              "      <td>0.886073</td>\n",
              "      <td>0.531452</td>\n",
              "      <td>0.311377</td>\n",
              "      <td>-0.021919</td>\n",
              "      <td>-0.713683</td>\n",
              "      <td>-0.532197</td>\n",
              "      <td>0.321097</td>\n",
              "      <td>0.904227</td>\n",
              "      <td>-0.421797</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.490473</td>\n",
              "      <td>-1.914407</td>\n",
              "      <td>-3.616364</td>\n",
              "      <td>-4.318823</td>\n",
              "      <td>-4.268016</td>\n",
              "      <td>-3.881110</td>\n",
              "      <td>-2.993280</td>\n",
              "      <td>-1.671131</td>\n",
              "      <td>-1.333884</td>\n",
              "      <td>-0.965629</td>\n",
              "      <td>...</td>\n",
              "      <td>0.350816</td>\n",
              "      <td>0.499111</td>\n",
              "      <td>0.600345</td>\n",
              "      <td>0.842069</td>\n",
              "      <td>0.952074</td>\n",
              "      <td>0.990133</td>\n",
              "      <td>1.086798</td>\n",
              "      <td>1.403011</td>\n",
              "      <td>-0.383564</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800232</td>\n",
              "      <td>-0.874252</td>\n",
              "      <td>-2.384761</td>\n",
              "      <td>-3.973292</td>\n",
              "      <td>-4.338224</td>\n",
              "      <td>-3.802422</td>\n",
              "      <td>-2.534510</td>\n",
              "      <td>-1.783423</td>\n",
              "      <td>-1.594450</td>\n",
              "      <td>-0.753199</td>\n",
              "      <td>...</td>\n",
              "      <td>1.148884</td>\n",
              "      <td>0.958434</td>\n",
              "      <td>1.059025</td>\n",
              "      <td>1.371682</td>\n",
              "      <td>1.277392</td>\n",
              "      <td>0.960304</td>\n",
              "      <td>0.971020</td>\n",
              "      <td>1.614392</td>\n",
              "      <td>1.421456</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>-0.478577</td>\n",
              "      <td>-1.779959</td>\n",
              "      <td>-2.398159</td>\n",
              "      <td>-3.170112</td>\n",
              "      <td>-3.559732</td>\n",
              "      <td>-3.573956</td>\n",
              "      <td>-2.989770</td>\n",
              "      <td>-2.270605</td>\n",
              "      <td>-1.688277</td>\n",
              "      <td>-1.359872</td>\n",
              "      <td>...</td>\n",
              "      <td>1.160885</td>\n",
              "      <td>1.456331</td>\n",
              "      <td>2.209421</td>\n",
              "      <td>2.507175</td>\n",
              "      <td>2.198534</td>\n",
              "      <td>1.705849</td>\n",
              "      <td>1.492642</td>\n",
              "      <td>1.561890</td>\n",
              "      <td>1.520161</td>\n",
              "      <td>b'4'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>-1.325210</td>\n",
              "      <td>-2.480992</td>\n",
              "      <td>-2.965356</td>\n",
              "      <td>-3.342392</td>\n",
              "      <td>-3.176351</td>\n",
              "      <td>-2.891528</td>\n",
              "      <td>-2.369679</td>\n",
              "      <td>-1.598750</td>\n",
              "      <td>-1.071751</td>\n",
              "      <td>-0.891843</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.172154</td>\n",
              "      <td>-0.864803</td>\n",
              "      <td>-1.549854</td>\n",
              "      <td>-2.460243</td>\n",
              "      <td>-3.366562</td>\n",
              "      <td>-3.466546</td>\n",
              "      <td>-2.718380</td>\n",
              "      <td>-1.855209</td>\n",
              "      <td>-1.539958</td>\n",
              "      <td>b'4'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>-0.021964</td>\n",
              "      <td>-0.912434</td>\n",
              "      <td>-1.903353</td>\n",
              "      <td>-2.662829</td>\n",
              "      <td>-3.122156</td>\n",
              "      <td>-3.451490</td>\n",
              "      <td>-3.392982</td>\n",
              "      <td>-2.929937</td>\n",
              "      <td>-2.256294</td>\n",
              "      <td>-1.690706</td>\n",
              "      <td>...</td>\n",
              "      <td>1.339479</td>\n",
              "      <td>1.457995</td>\n",
              "      <td>2.128078</td>\n",
              "      <td>2.630759</td>\n",
              "      <td>2.295748</td>\n",
              "      <td>1.764967</td>\n",
              "      <td>1.444280</td>\n",
              "      <td>1.432347</td>\n",
              "      <td>1.457028</td>\n",
              "      <td>b'4'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.288011</td>\n",
              "      <td>-1.098020</td>\n",
              "      <td>-2.500250</td>\n",
              "      <td>-3.598599</td>\n",
              "      <td>-3.650608</td>\n",
              "      <td>-3.281587</td>\n",
              "      <td>-2.231601</td>\n",
              "      <td>-1.250656</td>\n",
              "      <td>-1.072574</td>\n",
              "      <td>-0.434310</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029242</td>\n",
              "      <td>0.071414</td>\n",
              "      <td>0.118161</td>\n",
              "      <td>-0.071967</td>\n",
              "      <td>-0.171214</td>\n",
              "      <td>0.131211</td>\n",
              "      <td>0.049872</td>\n",
              "      <td>0.010915</td>\n",
              "      <td>-0.081534</td>\n",
              "      <td>b'5'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>-1.133674</td>\n",
              "      <td>-2.702941</td>\n",
              "      <td>-3.120979</td>\n",
              "      <td>-3.558669</td>\n",
              "      <td>-3.312442</td>\n",
              "      <td>-2.607641</td>\n",
              "      <td>-1.354939</td>\n",
              "      <td>-1.014740</td>\n",
              "      <td>-0.796023</td>\n",
              "      <td>-0.259599</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.206942</td>\n",
              "      <td>-2.941677</td>\n",
              "      <td>-2.557140</td>\n",
              "      <td>-1.487946</td>\n",
              "      <td>-1.118880</td>\n",
              "      <td>-0.737113</td>\n",
              "      <td>-0.110840</td>\n",
              "      <td>0.001858</td>\n",
              "      <td>-0.122639</td>\n",
              "      <td>b'5'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 141 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ae52f07-5658-464c-8a90-ffac5c4b0bf0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ae52f07-5658-464c-8a90-ffac5c4b0bf0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ae52f07-5658-464c-8a90-ffac5c4b0bf0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df1, df2])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "lxKazCIg3Rb4",
        "outputId": "86b65833-e396-4224-8dda-bc7ae0d8d3b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "0    3.690844  0.711414 -2.114091 -4.141007 -4.574472 -3.431909 -1.950791   \n",
              "1   -1.348132 -3.996038 -4.226750 -4.251187 -3.477953 -2.228422 -1.808488   \n",
              "2    1.024295 -0.590314 -1.916949 -2.806989 -3.527905 -3.638675 -2.779767   \n",
              "3    0.545657 -1.014383 -2.316698 -3.634040 -4.196857 -3.758093 -3.194444   \n",
              "4    0.661133 -1.552471 -3.124641 -4.313351 -4.017042 -3.005993 -1.832411   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "495 -0.478577 -1.779959 -2.398159 -3.170112 -3.559732 -3.573956 -2.989770   \n",
              "496 -1.325210 -2.480992 -2.965356 -3.342392 -3.176351 -2.891528 -2.369679   \n",
              "497 -0.021964 -0.912434 -1.903353 -2.662829 -3.122156 -3.451490 -3.392982   \n",
              "498  0.288011 -1.098020 -2.500250 -3.598599 -3.650608 -3.281587 -2.231601   \n",
              "499 -1.133674 -2.702941 -3.120979 -3.558669 -3.312442 -2.607641 -1.354939   \n",
              "\n",
              "         att8      att9     att10  ...    att132    att133    att134  \\\n",
              "0   -1.107067 -0.632322  0.334577  ...  0.022847  0.188937  0.480932   \n",
              "1   -1.534242 -0.779861 -0.397999  ...  1.570938  1.591394  1.549193   \n",
              "2   -2.019031 -1.980754 -1.440680  ...  0.443502  0.827582  1.237007   \n",
              "3   -2.221764 -1.588554 -1.202146  ...  0.777530  1.119240  0.902984   \n",
              "4   -1.503886 -1.071705 -0.521316  ...  1.280823  1.494315  1.618764   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "495 -2.270605 -1.688277 -1.359872  ...  1.160885  1.456331  2.209421   \n",
              "496 -1.598750 -1.071751 -0.891843  ... -0.172154 -0.864803 -1.549854   \n",
              "497 -2.929937 -2.256294 -1.690706  ...  1.339479  1.457995  2.128078   \n",
              "498 -1.250656 -1.072574 -0.434310  ... -0.029242  0.071414  0.118161   \n",
              "499 -1.014740 -0.796023 -0.259599  ... -3.206942 -2.941677 -2.557140   \n",
              "\n",
              "       att135    att136    att137    att138    att139    att140  target  \n",
              "0    0.629250  0.577291  0.665527  1.035997  1.492287 -1.905073    b'1'  \n",
              "1    1.193077  0.515134  0.126274  0.267532  1.071148 -1.164009    b'1'  \n",
              "2    1.235121  1.738103  1.800767  1.816301  1.473963  1.389767    b'1'  \n",
              "3    0.554098  0.497053  0.418116  0.703108  1.064602 -0.044853    b'1'  \n",
              "4    1.447449  1.238577  1.749692  1.986803  1.422756 -0.357784    b'1'  \n",
              "..        ...       ...       ...       ...       ...       ...     ...  \n",
              "495  2.507175  2.198534  1.705849  1.492642  1.561890  1.520161    b'4'  \n",
              "496 -2.460243 -3.366562 -3.466546 -2.718380 -1.855209 -1.539958    b'4'  \n",
              "497  2.630759  2.295748  1.764967  1.444280  1.432347  1.457028    b'4'  \n",
              "498 -0.071967 -0.171214  0.131211  0.049872  0.010915 -0.081534    b'5'  \n",
              "499 -1.487946 -1.118880 -0.737113 -0.110840  0.001858 -0.122639    b'5'  \n",
              "\n",
              "[5000 rows x 141 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a683b9e7-4110-458d-b2cd-bf17a451869f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>att1</th>\n",
              "      <th>att2</th>\n",
              "      <th>att3</th>\n",
              "      <th>att4</th>\n",
              "      <th>att5</th>\n",
              "      <th>att6</th>\n",
              "      <th>att7</th>\n",
              "      <th>att8</th>\n",
              "      <th>att9</th>\n",
              "      <th>att10</th>\n",
              "      <th>...</th>\n",
              "      <th>att132</th>\n",
              "      <th>att133</th>\n",
              "      <th>att134</th>\n",
              "      <th>att135</th>\n",
              "      <th>att136</th>\n",
              "      <th>att137</th>\n",
              "      <th>att138</th>\n",
              "      <th>att139</th>\n",
              "      <th>att140</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.690844</td>\n",
              "      <td>0.711414</td>\n",
              "      <td>-2.114091</td>\n",
              "      <td>-4.141007</td>\n",
              "      <td>-4.574472</td>\n",
              "      <td>-3.431909</td>\n",
              "      <td>-1.950791</td>\n",
              "      <td>-1.107067</td>\n",
              "      <td>-0.632322</td>\n",
              "      <td>0.334577</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022847</td>\n",
              "      <td>0.188937</td>\n",
              "      <td>0.480932</td>\n",
              "      <td>0.629250</td>\n",
              "      <td>0.577291</td>\n",
              "      <td>0.665527</td>\n",
              "      <td>1.035997</td>\n",
              "      <td>1.492287</td>\n",
              "      <td>-1.905073</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.348132</td>\n",
              "      <td>-3.996038</td>\n",
              "      <td>-4.226750</td>\n",
              "      <td>-4.251187</td>\n",
              "      <td>-3.477953</td>\n",
              "      <td>-2.228422</td>\n",
              "      <td>-1.808488</td>\n",
              "      <td>-1.534242</td>\n",
              "      <td>-0.779861</td>\n",
              "      <td>-0.397999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.570938</td>\n",
              "      <td>1.591394</td>\n",
              "      <td>1.549193</td>\n",
              "      <td>1.193077</td>\n",
              "      <td>0.515134</td>\n",
              "      <td>0.126274</td>\n",
              "      <td>0.267532</td>\n",
              "      <td>1.071148</td>\n",
              "      <td>-1.164009</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.024295</td>\n",
              "      <td>-0.590314</td>\n",
              "      <td>-1.916949</td>\n",
              "      <td>-2.806989</td>\n",
              "      <td>-3.527905</td>\n",
              "      <td>-3.638675</td>\n",
              "      <td>-2.779767</td>\n",
              "      <td>-2.019031</td>\n",
              "      <td>-1.980754</td>\n",
              "      <td>-1.440680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.443502</td>\n",
              "      <td>0.827582</td>\n",
              "      <td>1.237007</td>\n",
              "      <td>1.235121</td>\n",
              "      <td>1.738103</td>\n",
              "      <td>1.800767</td>\n",
              "      <td>1.816301</td>\n",
              "      <td>1.473963</td>\n",
              "      <td>1.389767</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.545657</td>\n",
              "      <td>-1.014383</td>\n",
              "      <td>-2.316698</td>\n",
              "      <td>-3.634040</td>\n",
              "      <td>-4.196857</td>\n",
              "      <td>-3.758093</td>\n",
              "      <td>-3.194444</td>\n",
              "      <td>-2.221764</td>\n",
              "      <td>-1.588554</td>\n",
              "      <td>-1.202146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777530</td>\n",
              "      <td>1.119240</td>\n",
              "      <td>0.902984</td>\n",
              "      <td>0.554098</td>\n",
              "      <td>0.497053</td>\n",
              "      <td>0.418116</td>\n",
              "      <td>0.703108</td>\n",
              "      <td>1.064602</td>\n",
              "      <td>-0.044853</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.661133</td>\n",
              "      <td>-1.552471</td>\n",
              "      <td>-3.124641</td>\n",
              "      <td>-4.313351</td>\n",
              "      <td>-4.017042</td>\n",
              "      <td>-3.005993</td>\n",
              "      <td>-1.832411</td>\n",
              "      <td>-1.503886</td>\n",
              "      <td>-1.071705</td>\n",
              "      <td>-0.521316</td>\n",
              "      <td>...</td>\n",
              "      <td>1.280823</td>\n",
              "      <td>1.494315</td>\n",
              "      <td>1.618764</td>\n",
              "      <td>1.447449</td>\n",
              "      <td>1.238577</td>\n",
              "      <td>1.749692</td>\n",
              "      <td>1.986803</td>\n",
              "      <td>1.422756</td>\n",
              "      <td>-0.357784</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>-0.478577</td>\n",
              "      <td>-1.779959</td>\n",
              "      <td>-2.398159</td>\n",
              "      <td>-3.170112</td>\n",
              "      <td>-3.559732</td>\n",
              "      <td>-3.573956</td>\n",
              "      <td>-2.989770</td>\n",
              "      <td>-2.270605</td>\n",
              "      <td>-1.688277</td>\n",
              "      <td>-1.359872</td>\n",
              "      <td>...</td>\n",
              "      <td>1.160885</td>\n",
              "      <td>1.456331</td>\n",
              "      <td>2.209421</td>\n",
              "      <td>2.507175</td>\n",
              "      <td>2.198534</td>\n",
              "      <td>1.705849</td>\n",
              "      <td>1.492642</td>\n",
              "      <td>1.561890</td>\n",
              "      <td>1.520161</td>\n",
              "      <td>b'4'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>-1.325210</td>\n",
              "      <td>-2.480992</td>\n",
              "      <td>-2.965356</td>\n",
              "      <td>-3.342392</td>\n",
              "      <td>-3.176351</td>\n",
              "      <td>-2.891528</td>\n",
              "      <td>-2.369679</td>\n",
              "      <td>-1.598750</td>\n",
              "      <td>-1.071751</td>\n",
              "      <td>-0.891843</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.172154</td>\n",
              "      <td>-0.864803</td>\n",
              "      <td>-1.549854</td>\n",
              "      <td>-2.460243</td>\n",
              "      <td>-3.366562</td>\n",
              "      <td>-3.466546</td>\n",
              "      <td>-2.718380</td>\n",
              "      <td>-1.855209</td>\n",
              "      <td>-1.539958</td>\n",
              "      <td>b'4'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>-0.021964</td>\n",
              "      <td>-0.912434</td>\n",
              "      <td>-1.903353</td>\n",
              "      <td>-2.662829</td>\n",
              "      <td>-3.122156</td>\n",
              "      <td>-3.451490</td>\n",
              "      <td>-3.392982</td>\n",
              "      <td>-2.929937</td>\n",
              "      <td>-2.256294</td>\n",
              "      <td>-1.690706</td>\n",
              "      <td>...</td>\n",
              "      <td>1.339479</td>\n",
              "      <td>1.457995</td>\n",
              "      <td>2.128078</td>\n",
              "      <td>2.630759</td>\n",
              "      <td>2.295748</td>\n",
              "      <td>1.764967</td>\n",
              "      <td>1.444280</td>\n",
              "      <td>1.432347</td>\n",
              "      <td>1.457028</td>\n",
              "      <td>b'4'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.288011</td>\n",
              "      <td>-1.098020</td>\n",
              "      <td>-2.500250</td>\n",
              "      <td>-3.598599</td>\n",
              "      <td>-3.650608</td>\n",
              "      <td>-3.281587</td>\n",
              "      <td>-2.231601</td>\n",
              "      <td>-1.250656</td>\n",
              "      <td>-1.072574</td>\n",
              "      <td>-0.434310</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029242</td>\n",
              "      <td>0.071414</td>\n",
              "      <td>0.118161</td>\n",
              "      <td>-0.071967</td>\n",
              "      <td>-0.171214</td>\n",
              "      <td>0.131211</td>\n",
              "      <td>0.049872</td>\n",
              "      <td>0.010915</td>\n",
              "      <td>-0.081534</td>\n",
              "      <td>b'5'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>-1.133674</td>\n",
              "      <td>-2.702941</td>\n",
              "      <td>-3.120979</td>\n",
              "      <td>-3.558669</td>\n",
              "      <td>-3.312442</td>\n",
              "      <td>-2.607641</td>\n",
              "      <td>-1.354939</td>\n",
              "      <td>-1.014740</td>\n",
              "      <td>-0.796023</td>\n",
              "      <td>-0.259599</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.206942</td>\n",
              "      <td>-2.941677</td>\n",
              "      <td>-2.557140</td>\n",
              "      <td>-1.487946</td>\n",
              "      <td>-1.118880</td>\n",
              "      <td>-0.737113</td>\n",
              "      <td>-0.110840</td>\n",
              "      <td>0.001858</td>\n",
              "      <td>-0.122639</td>\n",
              "      <td>b'5'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 141 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a683b9e7-4110-458d-b2cd-bf17a451869f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a683b9e7-4110-458d-b2cd-bf17a451869f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a683b9e7-4110-458d-b2cd-bf17a451869f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'] = df['target'].apply(lambda x: x.decode('utf-8').replace(\"b'\", \"\").replace(\"'\", \"\"))\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "zpOt3Yji3Rfh",
        "outputId": "31f2396c-28b4-437c-b5df-b955b024c32a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "0    3.690844  0.711414 -2.114091 -4.141007 -4.574472 -3.431909 -1.950791   \n",
              "1   -1.348132 -3.996038 -4.226750 -4.251187 -3.477953 -2.228422 -1.808488   \n",
              "2    1.024295 -0.590314 -1.916949 -2.806989 -3.527905 -3.638675 -2.779767   \n",
              "3    0.545657 -1.014383 -2.316698 -3.634040 -4.196857 -3.758093 -3.194444   \n",
              "4    0.661133 -1.552471 -3.124641 -4.313351 -4.017042 -3.005993 -1.832411   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "495 -0.478577 -1.779959 -2.398159 -3.170112 -3.559732 -3.573956 -2.989770   \n",
              "496 -1.325210 -2.480992 -2.965356 -3.342392 -3.176351 -2.891528 -2.369679   \n",
              "497 -0.021964 -0.912434 -1.903353 -2.662829 -3.122156 -3.451490 -3.392982   \n",
              "498  0.288011 -1.098020 -2.500250 -3.598599 -3.650608 -3.281587 -2.231601   \n",
              "499 -1.133674 -2.702941 -3.120979 -3.558669 -3.312442 -2.607641 -1.354939   \n",
              "\n",
              "         att8      att9     att10  ...    att132    att133    att134  \\\n",
              "0   -1.107067 -0.632322  0.334577  ...  0.022847  0.188937  0.480932   \n",
              "1   -1.534242 -0.779861 -0.397999  ...  1.570938  1.591394  1.549193   \n",
              "2   -2.019031 -1.980754 -1.440680  ...  0.443502  0.827582  1.237007   \n",
              "3   -2.221764 -1.588554 -1.202146  ...  0.777530  1.119240  0.902984   \n",
              "4   -1.503886 -1.071705 -0.521316  ...  1.280823  1.494315  1.618764   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "495 -2.270605 -1.688277 -1.359872  ...  1.160885  1.456331  2.209421   \n",
              "496 -1.598750 -1.071751 -0.891843  ... -0.172154 -0.864803 -1.549854   \n",
              "497 -2.929937 -2.256294 -1.690706  ...  1.339479  1.457995  2.128078   \n",
              "498 -1.250656 -1.072574 -0.434310  ... -0.029242  0.071414  0.118161   \n",
              "499 -1.014740 -0.796023 -0.259599  ... -3.206942 -2.941677 -2.557140   \n",
              "\n",
              "       att135    att136    att137    att138    att139    att140  target  \n",
              "0    0.629250  0.577291  0.665527  1.035997  1.492287 -1.905073       1  \n",
              "1    1.193077  0.515134  0.126274  0.267532  1.071148 -1.164009       1  \n",
              "2    1.235121  1.738103  1.800767  1.816301  1.473963  1.389767       1  \n",
              "3    0.554098  0.497053  0.418116  0.703108  1.064602 -0.044853       1  \n",
              "4    1.447449  1.238577  1.749692  1.986803  1.422756 -0.357784       1  \n",
              "..        ...       ...       ...       ...       ...       ...     ...  \n",
              "495  2.507175  2.198534  1.705849  1.492642  1.561890  1.520161       4  \n",
              "496 -2.460243 -3.366562 -3.466546 -2.718380 -1.855209 -1.539958       4  \n",
              "497  2.630759  2.295748  1.764967  1.444280  1.432347  1.457028       4  \n",
              "498 -0.071967 -0.171214  0.131211  0.049872  0.010915 -0.081534       5  \n",
              "499 -1.487946 -1.118880 -0.737113 -0.110840  0.001858 -0.122639       5  \n",
              "\n",
              "[5000 rows x 141 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da58eddd-1c83-4ee8-9b6b-c78ec66e48a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>att1</th>\n",
              "      <th>att2</th>\n",
              "      <th>att3</th>\n",
              "      <th>att4</th>\n",
              "      <th>att5</th>\n",
              "      <th>att6</th>\n",
              "      <th>att7</th>\n",
              "      <th>att8</th>\n",
              "      <th>att9</th>\n",
              "      <th>att10</th>\n",
              "      <th>...</th>\n",
              "      <th>att132</th>\n",
              "      <th>att133</th>\n",
              "      <th>att134</th>\n",
              "      <th>att135</th>\n",
              "      <th>att136</th>\n",
              "      <th>att137</th>\n",
              "      <th>att138</th>\n",
              "      <th>att139</th>\n",
              "      <th>att140</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.690844</td>\n",
              "      <td>0.711414</td>\n",
              "      <td>-2.114091</td>\n",
              "      <td>-4.141007</td>\n",
              "      <td>-4.574472</td>\n",
              "      <td>-3.431909</td>\n",
              "      <td>-1.950791</td>\n",
              "      <td>-1.107067</td>\n",
              "      <td>-0.632322</td>\n",
              "      <td>0.334577</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022847</td>\n",
              "      <td>0.188937</td>\n",
              "      <td>0.480932</td>\n",
              "      <td>0.629250</td>\n",
              "      <td>0.577291</td>\n",
              "      <td>0.665527</td>\n",
              "      <td>1.035997</td>\n",
              "      <td>1.492287</td>\n",
              "      <td>-1.905073</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.348132</td>\n",
              "      <td>-3.996038</td>\n",
              "      <td>-4.226750</td>\n",
              "      <td>-4.251187</td>\n",
              "      <td>-3.477953</td>\n",
              "      <td>-2.228422</td>\n",
              "      <td>-1.808488</td>\n",
              "      <td>-1.534242</td>\n",
              "      <td>-0.779861</td>\n",
              "      <td>-0.397999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.570938</td>\n",
              "      <td>1.591394</td>\n",
              "      <td>1.549193</td>\n",
              "      <td>1.193077</td>\n",
              "      <td>0.515134</td>\n",
              "      <td>0.126274</td>\n",
              "      <td>0.267532</td>\n",
              "      <td>1.071148</td>\n",
              "      <td>-1.164009</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.024295</td>\n",
              "      <td>-0.590314</td>\n",
              "      <td>-1.916949</td>\n",
              "      <td>-2.806989</td>\n",
              "      <td>-3.527905</td>\n",
              "      <td>-3.638675</td>\n",
              "      <td>-2.779767</td>\n",
              "      <td>-2.019031</td>\n",
              "      <td>-1.980754</td>\n",
              "      <td>-1.440680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.443502</td>\n",
              "      <td>0.827582</td>\n",
              "      <td>1.237007</td>\n",
              "      <td>1.235121</td>\n",
              "      <td>1.738103</td>\n",
              "      <td>1.800767</td>\n",
              "      <td>1.816301</td>\n",
              "      <td>1.473963</td>\n",
              "      <td>1.389767</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.545657</td>\n",
              "      <td>-1.014383</td>\n",
              "      <td>-2.316698</td>\n",
              "      <td>-3.634040</td>\n",
              "      <td>-4.196857</td>\n",
              "      <td>-3.758093</td>\n",
              "      <td>-3.194444</td>\n",
              "      <td>-2.221764</td>\n",
              "      <td>-1.588554</td>\n",
              "      <td>-1.202146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777530</td>\n",
              "      <td>1.119240</td>\n",
              "      <td>0.902984</td>\n",
              "      <td>0.554098</td>\n",
              "      <td>0.497053</td>\n",
              "      <td>0.418116</td>\n",
              "      <td>0.703108</td>\n",
              "      <td>1.064602</td>\n",
              "      <td>-0.044853</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.661133</td>\n",
              "      <td>-1.552471</td>\n",
              "      <td>-3.124641</td>\n",
              "      <td>-4.313351</td>\n",
              "      <td>-4.017042</td>\n",
              "      <td>-3.005993</td>\n",
              "      <td>-1.832411</td>\n",
              "      <td>-1.503886</td>\n",
              "      <td>-1.071705</td>\n",
              "      <td>-0.521316</td>\n",
              "      <td>...</td>\n",
              "      <td>1.280823</td>\n",
              "      <td>1.494315</td>\n",
              "      <td>1.618764</td>\n",
              "      <td>1.447449</td>\n",
              "      <td>1.238577</td>\n",
              "      <td>1.749692</td>\n",
              "      <td>1.986803</td>\n",
              "      <td>1.422756</td>\n",
              "      <td>-0.357784</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>-0.478577</td>\n",
              "      <td>-1.779959</td>\n",
              "      <td>-2.398159</td>\n",
              "      <td>-3.170112</td>\n",
              "      <td>-3.559732</td>\n",
              "      <td>-3.573956</td>\n",
              "      <td>-2.989770</td>\n",
              "      <td>-2.270605</td>\n",
              "      <td>-1.688277</td>\n",
              "      <td>-1.359872</td>\n",
              "      <td>...</td>\n",
              "      <td>1.160885</td>\n",
              "      <td>1.456331</td>\n",
              "      <td>2.209421</td>\n",
              "      <td>2.507175</td>\n",
              "      <td>2.198534</td>\n",
              "      <td>1.705849</td>\n",
              "      <td>1.492642</td>\n",
              "      <td>1.561890</td>\n",
              "      <td>1.520161</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>-1.325210</td>\n",
              "      <td>-2.480992</td>\n",
              "      <td>-2.965356</td>\n",
              "      <td>-3.342392</td>\n",
              "      <td>-3.176351</td>\n",
              "      <td>-2.891528</td>\n",
              "      <td>-2.369679</td>\n",
              "      <td>-1.598750</td>\n",
              "      <td>-1.071751</td>\n",
              "      <td>-0.891843</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.172154</td>\n",
              "      <td>-0.864803</td>\n",
              "      <td>-1.549854</td>\n",
              "      <td>-2.460243</td>\n",
              "      <td>-3.366562</td>\n",
              "      <td>-3.466546</td>\n",
              "      <td>-2.718380</td>\n",
              "      <td>-1.855209</td>\n",
              "      <td>-1.539958</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>-0.021964</td>\n",
              "      <td>-0.912434</td>\n",
              "      <td>-1.903353</td>\n",
              "      <td>-2.662829</td>\n",
              "      <td>-3.122156</td>\n",
              "      <td>-3.451490</td>\n",
              "      <td>-3.392982</td>\n",
              "      <td>-2.929937</td>\n",
              "      <td>-2.256294</td>\n",
              "      <td>-1.690706</td>\n",
              "      <td>...</td>\n",
              "      <td>1.339479</td>\n",
              "      <td>1.457995</td>\n",
              "      <td>2.128078</td>\n",
              "      <td>2.630759</td>\n",
              "      <td>2.295748</td>\n",
              "      <td>1.764967</td>\n",
              "      <td>1.444280</td>\n",
              "      <td>1.432347</td>\n",
              "      <td>1.457028</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.288011</td>\n",
              "      <td>-1.098020</td>\n",
              "      <td>-2.500250</td>\n",
              "      <td>-3.598599</td>\n",
              "      <td>-3.650608</td>\n",
              "      <td>-3.281587</td>\n",
              "      <td>-2.231601</td>\n",
              "      <td>-1.250656</td>\n",
              "      <td>-1.072574</td>\n",
              "      <td>-0.434310</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029242</td>\n",
              "      <td>0.071414</td>\n",
              "      <td>0.118161</td>\n",
              "      <td>-0.071967</td>\n",
              "      <td>-0.171214</td>\n",
              "      <td>0.131211</td>\n",
              "      <td>0.049872</td>\n",
              "      <td>0.010915</td>\n",
              "      <td>-0.081534</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>-1.133674</td>\n",
              "      <td>-2.702941</td>\n",
              "      <td>-3.120979</td>\n",
              "      <td>-3.558669</td>\n",
              "      <td>-3.312442</td>\n",
              "      <td>-2.607641</td>\n",
              "      <td>-1.354939</td>\n",
              "      <td>-1.014740</td>\n",
              "      <td>-0.796023</td>\n",
              "      <td>-0.259599</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.206942</td>\n",
              "      <td>-2.941677</td>\n",
              "      <td>-2.557140</td>\n",
              "      <td>-1.487946</td>\n",
              "      <td>-1.118880</td>\n",
              "      <td>-0.737113</td>\n",
              "      <td>-0.110840</td>\n",
              "      <td>0.001858</td>\n",
              "      <td>-0.122639</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 141 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da58eddd-1c83-4ee8-9b6b-c78ec66e48a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da58eddd-1c83-4ee8-9b6b-c78ec66e48a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da58eddd-1c83-4ee8-9b6b-c78ec66e48a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMyNQKL8CQXg",
        "outputId": "16177145-f7a4-43f3-eeca-ea3eb11387e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "att1      float64\n",
              "att2      float64\n",
              "att3      float64\n",
              "att4      float64\n",
              "att5      float64\n",
              "           ...   \n",
              "att137    float64\n",
              "att138    float64\n",
              "att139    float64\n",
              "att140    float64\n",
              "target     object\n",
              "Length: 141, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'] = df['target'].astype(float)"
      ],
      "metadata": {
        "id": "G8Etu_TlUbDE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdenuX6mUfps",
        "outputId": "1d3270ec-1626-4592-d005-cda2a413a154"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "att1      float64\n",
              "att2      float64\n",
              "att3      float64\n",
              "att4      float64\n",
              "att5      float64\n",
              "           ...   \n",
              "att137    float64\n",
              "att138    float64\n",
              "att139    float64\n",
              "att140    float64\n",
              "target    float64\n",
              "Length: 141, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning dataset"
      ],
      "metadata": {
        "id": "RShaXsMu3oCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['target'].isnull().sum())\n",
        "print(df['target'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbso9IDG3RiI",
        "outputId": "a451aa24-7a7e-4661-b44c-11593e0c1527"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[1. 2. 3. 4. 5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "id_to_label = {\n",
        "    '1': \"Normal\",\n",
        "    '2': \"Artial Premature\",\n",
        "    '3': \"Premature ventricular contraction\",\n",
        "    '4': \"Fusion of ventricular and normal\",\n",
        "    '5': \"Fusion of paced and normal\"\n",
        "}\n",
        "df['target'] = df['target'].map(id_to_label)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-q0e6y5_3Rkw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7b6df29e-2afc-425b-9d74-df7cfd7177eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nid_to_label = {\\n    \\'1\\': \"Normal\",\\n    \\'2\\': \"Artial Premature\",\\n    \\'3\\': \"Premature ventricular contraction\",\\n    \\'4\\': \"Fusion of ventricular and normal\",\\n    \\'5\\': \"Fusion of paced and normal\"\\n}\\ndf[\\'target\\'] = df[\\'target\\'].map(id_to_label)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "usmION7L3RnQ",
        "outputId": "50427d8b-9d92-42dc-87ec-39c826e26b77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       att1      att2      att3      att4      att5      att6      att7  \\\n",
              "0  3.690844  0.711414 -2.114091 -4.141007 -4.574472 -3.431909 -1.950791   \n",
              "1 -1.348132 -3.996038 -4.226750 -4.251187 -3.477953 -2.228422 -1.808488   \n",
              "2  1.024295 -0.590314 -1.916949 -2.806989 -3.527905 -3.638675 -2.779767   \n",
              "3  0.545657 -1.014383 -2.316698 -3.634040 -4.196857 -3.758093 -3.194444   \n",
              "4  0.661133 -1.552471 -3.124641 -4.313351 -4.017042 -3.005993 -1.832411   \n",
              "\n",
              "       att8      att9     att10  ...    att132    att133    att134    att135  \\\n",
              "0 -1.107067 -0.632322  0.334577  ...  0.022847  0.188937  0.480932  0.629250   \n",
              "1 -1.534242 -0.779861 -0.397999  ...  1.570938  1.591394  1.549193  1.193077   \n",
              "2 -2.019031 -1.980754 -1.440680  ...  0.443502  0.827582  1.237007  1.235121   \n",
              "3 -2.221764 -1.588554 -1.202146  ...  0.777530  1.119240  0.902984  0.554098   \n",
              "4 -1.503886 -1.071705 -0.521316  ...  1.280823  1.494315  1.618764  1.447449   \n",
              "\n",
              "     att136    att137    att138    att139    att140  target  \n",
              "0  0.577291  0.665527  1.035997  1.492287 -1.905073     1.0  \n",
              "1  0.515134  0.126274  0.267532  1.071148 -1.164009     1.0  \n",
              "2  1.738103  1.800767  1.816301  1.473963  1.389767     1.0  \n",
              "3  0.497053  0.418116  0.703108  1.064602 -0.044853     1.0  \n",
              "4  1.238577  1.749692  1.986803  1.422756 -0.357784     1.0  \n",
              "\n",
              "[5 rows x 141 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b448203a-f92e-4ca6-9bc9-73a5ddbec84a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>att1</th>\n",
              "      <th>att2</th>\n",
              "      <th>att3</th>\n",
              "      <th>att4</th>\n",
              "      <th>att5</th>\n",
              "      <th>att6</th>\n",
              "      <th>att7</th>\n",
              "      <th>att8</th>\n",
              "      <th>att9</th>\n",
              "      <th>att10</th>\n",
              "      <th>...</th>\n",
              "      <th>att132</th>\n",
              "      <th>att133</th>\n",
              "      <th>att134</th>\n",
              "      <th>att135</th>\n",
              "      <th>att136</th>\n",
              "      <th>att137</th>\n",
              "      <th>att138</th>\n",
              "      <th>att139</th>\n",
              "      <th>att140</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.690844</td>\n",
              "      <td>0.711414</td>\n",
              "      <td>-2.114091</td>\n",
              "      <td>-4.141007</td>\n",
              "      <td>-4.574472</td>\n",
              "      <td>-3.431909</td>\n",
              "      <td>-1.950791</td>\n",
              "      <td>-1.107067</td>\n",
              "      <td>-0.632322</td>\n",
              "      <td>0.334577</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022847</td>\n",
              "      <td>0.188937</td>\n",
              "      <td>0.480932</td>\n",
              "      <td>0.629250</td>\n",
              "      <td>0.577291</td>\n",
              "      <td>0.665527</td>\n",
              "      <td>1.035997</td>\n",
              "      <td>1.492287</td>\n",
              "      <td>-1.905073</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.348132</td>\n",
              "      <td>-3.996038</td>\n",
              "      <td>-4.226750</td>\n",
              "      <td>-4.251187</td>\n",
              "      <td>-3.477953</td>\n",
              "      <td>-2.228422</td>\n",
              "      <td>-1.808488</td>\n",
              "      <td>-1.534242</td>\n",
              "      <td>-0.779861</td>\n",
              "      <td>-0.397999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.570938</td>\n",
              "      <td>1.591394</td>\n",
              "      <td>1.549193</td>\n",
              "      <td>1.193077</td>\n",
              "      <td>0.515134</td>\n",
              "      <td>0.126274</td>\n",
              "      <td>0.267532</td>\n",
              "      <td>1.071148</td>\n",
              "      <td>-1.164009</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.024295</td>\n",
              "      <td>-0.590314</td>\n",
              "      <td>-1.916949</td>\n",
              "      <td>-2.806989</td>\n",
              "      <td>-3.527905</td>\n",
              "      <td>-3.638675</td>\n",
              "      <td>-2.779767</td>\n",
              "      <td>-2.019031</td>\n",
              "      <td>-1.980754</td>\n",
              "      <td>-1.440680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.443502</td>\n",
              "      <td>0.827582</td>\n",
              "      <td>1.237007</td>\n",
              "      <td>1.235121</td>\n",
              "      <td>1.738103</td>\n",
              "      <td>1.800767</td>\n",
              "      <td>1.816301</td>\n",
              "      <td>1.473963</td>\n",
              "      <td>1.389767</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.545657</td>\n",
              "      <td>-1.014383</td>\n",
              "      <td>-2.316698</td>\n",
              "      <td>-3.634040</td>\n",
              "      <td>-4.196857</td>\n",
              "      <td>-3.758093</td>\n",
              "      <td>-3.194444</td>\n",
              "      <td>-2.221764</td>\n",
              "      <td>-1.588554</td>\n",
              "      <td>-1.202146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777530</td>\n",
              "      <td>1.119240</td>\n",
              "      <td>0.902984</td>\n",
              "      <td>0.554098</td>\n",
              "      <td>0.497053</td>\n",
              "      <td>0.418116</td>\n",
              "      <td>0.703108</td>\n",
              "      <td>1.064602</td>\n",
              "      <td>-0.044853</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.661133</td>\n",
              "      <td>-1.552471</td>\n",
              "      <td>-3.124641</td>\n",
              "      <td>-4.313351</td>\n",
              "      <td>-4.017042</td>\n",
              "      <td>-3.005993</td>\n",
              "      <td>-1.832411</td>\n",
              "      <td>-1.503886</td>\n",
              "      <td>-1.071705</td>\n",
              "      <td>-0.521316</td>\n",
              "      <td>...</td>\n",
              "      <td>1.280823</td>\n",
              "      <td>1.494315</td>\n",
              "      <td>1.618764</td>\n",
              "      <td>1.447449</td>\n",
              "      <td>1.238577</td>\n",
              "      <td>1.749692</td>\n",
              "      <td>1.986803</td>\n",
              "      <td>1.422756</td>\n",
              "      <td>-0.357784</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 141 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b448203a-f92e-4ca6-9bc9-73a5ddbec84a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b448203a-f92e-4ca6-9bc9-73a5ddbec84a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b448203a-f92e-4ca6-9bc9-73a5ddbec84a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augementation (SMOTE resampling)"
      ],
      "metadata": {
        "id": "piJBezBq30VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-1xV5X63Rpo",
        "outputId": "df0f2536-9051-48b7-ec44-f75d4cf84e3d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    2919\n",
              "2.0    1767\n",
              "4.0     194\n",
              "3.0      96\n",
              "5.0      24\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentages = [count / df.shape[0] * 100 for count in df['target'].value_counts()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "sns.countplot(\n",
        "    x=df['target'],\n",
        "    ax=ax,\n",
        "    palette=\"bright\",\n",
        "    order=df['target'].value_counts().index\n",
        ")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=15);\n",
        "\n",
        "for percentage, count, p in zip(\n",
        "    percentages,\n",
        "    df['target'].value_counts(sort=True).values,\n",
        "    ax.patches):\n",
        "    \n",
        "    percentage = f'{np.round(percentage, 2)}%'\n",
        "    x = p.get_x() + p.get_width() / 2 - 0.4\n",
        "    y = p.get_y() + p.get_height()\n",
        "    ax.annotate(str(percentage)+\" / \"+str(count), (x, y), fontsize=12, fontweight='bold')\n",
        "    \n",
        "plt.savefig('data_dist.png', facecolor='w', edgecolor='w', format='png',\n",
        "        transparent=False, bbox_inches='tight', pad_inches=0.1)\n",
        "plt.savefig('data_dist.svg', facecolor='w', edgecolor='w', format='svg',\n",
        "        transparent=False, bbox_inches='tight', pad_inches=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "WwR6prNd3RsU",
        "outputId": "b5b4b718-60fe-4f11-fc6e-cc53d99dbe4a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
        "plt.pie(df['target'].value_counts(), labels=['Normal','Artial Premature','Premature ventricular contraction','Fusion of ventricular and normal','Fusion of paced and normal'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "C_KcZ4893RvI",
        "outputId": "bd2220e4-0188-458d-b65f-a8e26523868e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_1 = df[df[\"target\"] == 1]\n",
        "data_2 = df[df[\"target\"] == 2]\n",
        "data_3 = df[df[\"target\"] == 3]\n",
        "data_4 = df[df[\"target\"] == 4]\n",
        "data_5 = df[df[\"target\"] == 5]\n"
      ],
      "metadata": {
        "id": "htvt4F8x3RyA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "data_1_resample = resample(data_1, n_samples=20000, \n",
        "                           random_state=123, replace=True)\n",
        "data_2_resample = resample(data_2, n_samples=20000, \n",
        "                           random_state=123, replace=True)\n",
        "data_3_resample = resample(data_3, n_samples=20000, \n",
        "                           random_state=123, replace=True)\n",
        "data_4_resample = resample(data_4, n_samples=20000, \n",
        "                           random_state=123, replace=True)\n",
        "data_5_resample = resample(data_5, n_samples=20000, \n",
        "                           random_state=123, replace=True)"
      ],
      "metadata": {
        "id": "i_itgcHl3R0g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = pd.concat([data_5_resample, data_1_resample, data_2_resample, data_3_resample, \n",
        "                          data_4_resample])"
      ],
      "metadata": {
        "id": "KjsHlCI53R3Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "MEDsL4kW3R6A",
        "outputId": "95430ca8-c807-4505-b170-8013995e76d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          att1      att2      att3      att4      att5      att6      att7  \\\n",
              "3360  0.366155 -0.813771 -1.503020 -2.856105 -3.019006 -3.216679 -2.798837   \n",
              "2813 -0.084942 -0.960786 -1.301019 -1.712707 -2.284085 -2.714194 -3.003980   \n",
              "2813 -0.084942 -0.960786 -1.301019 -1.712707 -2.284085 -2.714194 -3.003980   \n",
              "2929 -0.041860  0.199407  0.652002  0.899509  1.227280  1.105721  1.086423   \n",
              "3507 -0.771630 -2.232628 -3.152674 -3.581292 -3.378039 -3.094399 -2.536773   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "3921 -2.036213 -2.935980 -3.638401 -3.892018 -3.801315 -3.216726 -2.455610   \n",
              "3689 -0.052029 -1.166668 -1.760398 -2.468790 -2.846996 -3.081430 -2.920062   \n",
              "2912  0.423644 -0.556992 -1.064779 -2.085770 -2.653392 -3.125218 -3.163182   \n",
              "3091  0.897485  0.257502 -0.437376 -1.005904 -1.735327 -2.252272 -2.428399   \n",
              "2807 -0.221889 -0.937982 -1.237525 -1.784462 -2.075887 -2.445110 -2.397587   \n",
              "\n",
              "          att8      att9     att10  ...    att132    att133    att134  \\\n",
              "3360 -2.167081 -1.407703 -0.830927  ... -2.385297 -2.742860 -3.197087   \n",
              "2813 -3.300124 -3.514020 -3.504454  ...  0.665040  0.664337  0.618862   \n",
              "2813 -3.300124 -3.514020 -3.504454  ...  0.665040  0.664337  0.618862   \n",
              "2929  1.153592  1.148754  1.174345  ...  0.799520  0.878151  0.913705   \n",
              "3507 -1.748678 -1.042883 -0.975582  ... -1.170622 -1.515581 -2.103121   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "3921 -1.717345 -1.494549 -1.304859  ...  0.954609  0.784390  0.698442   \n",
              "3689 -2.597700 -2.206110 -1.547013  ... -2.544778 -3.215986 -3.650375   \n",
              "2912 -3.068716 -2.797393 -2.153900  ...  2.360101  2.854680  2.707110   \n",
              "3091 -2.366986 -1.915568 -1.565518  ...  2.012756  2.019352  2.415682   \n",
              "2807 -2.119287 -1.883918 -1.511419  ... -0.438857 -0.691526 -1.338715   \n",
              "\n",
              "        att135    att136    att137    att138    att139    att140  target  \n",
              "3360 -3.343658 -3.084722 -2.672918 -1.052041 -0.590285  1.300554     5.0  \n",
              "2813  0.701566  0.867772  0.759582  0.428206  0.571943  1.514304     5.0  \n",
              "2813  0.701566  0.867772  0.759582  0.428206  0.571943  1.514304     5.0  \n",
              "2929  0.977138  1.002193  0.915948  0.918284  0.792190  0.805242     5.0  \n",
              "3507 -2.825158 -3.409660 -3.322502 -2.464701 -1.016952  0.185271     5.0  \n",
              "...        ...       ...       ...       ...       ...       ...     ...  \n",
              "3921  0.653446  0.785857  0.931829  1.158112  1.158192  0.270931     4.0  \n",
              "3689 -3.411444 -2.814130 -1.826358 -0.689839 -0.515141  0.438252     4.0  \n",
              "2912  2.033384  1.600893  1.280609  1.600487  1.042431  1.237363     4.0  \n",
              "3091  2.880372  2.900458  2.353758  1.731006  1.572376  1.723486     4.0  \n",
              "2807 -2.052960 -2.664535 -3.786363 -3.850222 -5.341570 -3.768831     4.0  \n",
              "\n",
              "[100000 rows x 141 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe47481d-07e6-4311-b9db-6fc8be2050b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>att1</th>\n",
              "      <th>att2</th>\n",
              "      <th>att3</th>\n",
              "      <th>att4</th>\n",
              "      <th>att5</th>\n",
              "      <th>att6</th>\n",
              "      <th>att7</th>\n",
              "      <th>att8</th>\n",
              "      <th>att9</th>\n",
              "      <th>att10</th>\n",
              "      <th>...</th>\n",
              "      <th>att132</th>\n",
              "      <th>att133</th>\n",
              "      <th>att134</th>\n",
              "      <th>att135</th>\n",
              "      <th>att136</th>\n",
              "      <th>att137</th>\n",
              "      <th>att138</th>\n",
              "      <th>att139</th>\n",
              "      <th>att140</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3360</th>\n",
              "      <td>0.366155</td>\n",
              "      <td>-0.813771</td>\n",
              "      <td>-1.503020</td>\n",
              "      <td>-2.856105</td>\n",
              "      <td>-3.019006</td>\n",
              "      <td>-3.216679</td>\n",
              "      <td>-2.798837</td>\n",
              "      <td>-2.167081</td>\n",
              "      <td>-1.407703</td>\n",
              "      <td>-0.830927</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.385297</td>\n",
              "      <td>-2.742860</td>\n",
              "      <td>-3.197087</td>\n",
              "      <td>-3.343658</td>\n",
              "      <td>-3.084722</td>\n",
              "      <td>-2.672918</td>\n",
              "      <td>-1.052041</td>\n",
              "      <td>-0.590285</td>\n",
              "      <td>1.300554</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2813</th>\n",
              "      <td>-0.084942</td>\n",
              "      <td>-0.960786</td>\n",
              "      <td>-1.301019</td>\n",
              "      <td>-1.712707</td>\n",
              "      <td>-2.284085</td>\n",
              "      <td>-2.714194</td>\n",
              "      <td>-3.003980</td>\n",
              "      <td>-3.300124</td>\n",
              "      <td>-3.514020</td>\n",
              "      <td>-3.504454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.665040</td>\n",
              "      <td>0.664337</td>\n",
              "      <td>0.618862</td>\n",
              "      <td>0.701566</td>\n",
              "      <td>0.867772</td>\n",
              "      <td>0.759582</td>\n",
              "      <td>0.428206</td>\n",
              "      <td>0.571943</td>\n",
              "      <td>1.514304</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2813</th>\n",
              "      <td>-0.084942</td>\n",
              "      <td>-0.960786</td>\n",
              "      <td>-1.301019</td>\n",
              "      <td>-1.712707</td>\n",
              "      <td>-2.284085</td>\n",
              "      <td>-2.714194</td>\n",
              "      <td>-3.003980</td>\n",
              "      <td>-3.300124</td>\n",
              "      <td>-3.514020</td>\n",
              "      <td>-3.504454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.665040</td>\n",
              "      <td>0.664337</td>\n",
              "      <td>0.618862</td>\n",
              "      <td>0.701566</td>\n",
              "      <td>0.867772</td>\n",
              "      <td>0.759582</td>\n",
              "      <td>0.428206</td>\n",
              "      <td>0.571943</td>\n",
              "      <td>1.514304</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>-0.041860</td>\n",
              "      <td>0.199407</td>\n",
              "      <td>0.652002</td>\n",
              "      <td>0.899509</td>\n",
              "      <td>1.227280</td>\n",
              "      <td>1.105721</td>\n",
              "      <td>1.086423</td>\n",
              "      <td>1.153592</td>\n",
              "      <td>1.148754</td>\n",
              "      <td>1.174345</td>\n",
              "      <td>...</td>\n",
              "      <td>0.799520</td>\n",
              "      <td>0.878151</td>\n",
              "      <td>0.913705</td>\n",
              "      <td>0.977138</td>\n",
              "      <td>1.002193</td>\n",
              "      <td>0.915948</td>\n",
              "      <td>0.918284</td>\n",
              "      <td>0.792190</td>\n",
              "      <td>0.805242</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3507</th>\n",
              "      <td>-0.771630</td>\n",
              "      <td>-2.232628</td>\n",
              "      <td>-3.152674</td>\n",
              "      <td>-3.581292</td>\n",
              "      <td>-3.378039</td>\n",
              "      <td>-3.094399</td>\n",
              "      <td>-2.536773</td>\n",
              "      <td>-1.748678</td>\n",
              "      <td>-1.042883</td>\n",
              "      <td>-0.975582</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.170622</td>\n",
              "      <td>-1.515581</td>\n",
              "      <td>-2.103121</td>\n",
              "      <td>-2.825158</td>\n",
              "      <td>-3.409660</td>\n",
              "      <td>-3.322502</td>\n",
              "      <td>-2.464701</td>\n",
              "      <td>-1.016952</td>\n",
              "      <td>0.185271</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3921</th>\n",
              "      <td>-2.036213</td>\n",
              "      <td>-2.935980</td>\n",
              "      <td>-3.638401</td>\n",
              "      <td>-3.892018</td>\n",
              "      <td>-3.801315</td>\n",
              "      <td>-3.216726</td>\n",
              "      <td>-2.455610</td>\n",
              "      <td>-1.717345</td>\n",
              "      <td>-1.494549</td>\n",
              "      <td>-1.304859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.954609</td>\n",
              "      <td>0.784390</td>\n",
              "      <td>0.698442</td>\n",
              "      <td>0.653446</td>\n",
              "      <td>0.785857</td>\n",
              "      <td>0.931829</td>\n",
              "      <td>1.158112</td>\n",
              "      <td>1.158192</td>\n",
              "      <td>0.270931</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3689</th>\n",
              "      <td>-0.052029</td>\n",
              "      <td>-1.166668</td>\n",
              "      <td>-1.760398</td>\n",
              "      <td>-2.468790</td>\n",
              "      <td>-2.846996</td>\n",
              "      <td>-3.081430</td>\n",
              "      <td>-2.920062</td>\n",
              "      <td>-2.597700</td>\n",
              "      <td>-2.206110</td>\n",
              "      <td>-1.547013</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.544778</td>\n",
              "      <td>-3.215986</td>\n",
              "      <td>-3.650375</td>\n",
              "      <td>-3.411444</td>\n",
              "      <td>-2.814130</td>\n",
              "      <td>-1.826358</td>\n",
              "      <td>-0.689839</td>\n",
              "      <td>-0.515141</td>\n",
              "      <td>0.438252</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2912</th>\n",
              "      <td>0.423644</td>\n",
              "      <td>-0.556992</td>\n",
              "      <td>-1.064779</td>\n",
              "      <td>-2.085770</td>\n",
              "      <td>-2.653392</td>\n",
              "      <td>-3.125218</td>\n",
              "      <td>-3.163182</td>\n",
              "      <td>-3.068716</td>\n",
              "      <td>-2.797393</td>\n",
              "      <td>-2.153900</td>\n",
              "      <td>...</td>\n",
              "      <td>2.360101</td>\n",
              "      <td>2.854680</td>\n",
              "      <td>2.707110</td>\n",
              "      <td>2.033384</td>\n",
              "      <td>1.600893</td>\n",
              "      <td>1.280609</td>\n",
              "      <td>1.600487</td>\n",
              "      <td>1.042431</td>\n",
              "      <td>1.237363</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3091</th>\n",
              "      <td>0.897485</td>\n",
              "      <td>0.257502</td>\n",
              "      <td>-0.437376</td>\n",
              "      <td>-1.005904</td>\n",
              "      <td>-1.735327</td>\n",
              "      <td>-2.252272</td>\n",
              "      <td>-2.428399</td>\n",
              "      <td>-2.366986</td>\n",
              "      <td>-1.915568</td>\n",
              "      <td>-1.565518</td>\n",
              "      <td>...</td>\n",
              "      <td>2.012756</td>\n",
              "      <td>2.019352</td>\n",
              "      <td>2.415682</td>\n",
              "      <td>2.880372</td>\n",
              "      <td>2.900458</td>\n",
              "      <td>2.353758</td>\n",
              "      <td>1.731006</td>\n",
              "      <td>1.572376</td>\n",
              "      <td>1.723486</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2807</th>\n",
              "      <td>-0.221889</td>\n",
              "      <td>-0.937982</td>\n",
              "      <td>-1.237525</td>\n",
              "      <td>-1.784462</td>\n",
              "      <td>-2.075887</td>\n",
              "      <td>-2.445110</td>\n",
              "      <td>-2.397587</td>\n",
              "      <td>-2.119287</td>\n",
              "      <td>-1.883918</td>\n",
              "      <td>-1.511419</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.438857</td>\n",
              "      <td>-0.691526</td>\n",
              "      <td>-1.338715</td>\n",
              "      <td>-2.052960</td>\n",
              "      <td>-2.664535</td>\n",
              "      <td>-3.786363</td>\n",
              "      <td>-3.850222</td>\n",
              "      <td>-5.341570</td>\n",
              "      <td>-3.768831</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 141 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe47481d-07e6-4311-b9db-6fc8be2050b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe47481d-07e6-4311-b9db-6fc8be2050b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe47481d-07e6-4311-b9db-6fc8be2050b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = train_dataset"
      ],
      "metadata": {
        "id": "7EMptV8h3R8w"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df.iloc[:, -1]\n",
        "\n",
        "X = df.iloc[:, 0:-1]\n"
      ],
      "metadata": {
        "id": "GfHBuL2r3R_Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentages = [count / Y.shape[0] * 100 for count in Y.value_counts()]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "sns.countplot(\n",
        "    x=Y,\n",
        "    ax=ax,\n",
        "    palette=\"bright\",\n",
        "    order=Y.value_counts().index\n",
        ")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=15);\n",
        "\n",
        "for percentage, count, p in zip(\n",
        "    percentages,\n",
        "    Y.value_counts(sort=True).values,\n",
        "    ax.patches):\n",
        "    \n",
        "    percentage = f'{np.round(percentage, 2)}%'\n",
        "    x = p.get_x() + p.get_width() / 2 - 0.4\n",
        "    y = p.get_y() + p.get_height()\n",
        "    ax.annotate(str(percentage)+\" / \"+str(count), (x, y), fontsize=12, fontweight='bold')\n",
        "    \n",
        "plt.savefig('data_dist.png', facecolor='w', edgecolor='w', format='png',\n",
        "        transparent=False, bbox_inches='tight', pad_inches=0.1)\n",
        "plt.savefig('data_dist.svg', facecolor='w', edgecolor='w', format='svg',\n",
        "        transparent=False, bbox_inches='tight', pad_inches=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "cSHjJPXn3SCB",
        "outputId": "bee6ebd4-2043-4daf-f0be-50faadc952bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
        "plt.pie(Y.value_counts(), labels=['Normal','Artial Premature','Premature ventricular contraction','Fusion of ventricular and normal','Fusion of paced and normal'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "sNjykmJ43SEq",
        "outputId": "08892e5d-5c63-4142-8d38-6d97f3682612"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting resampled dataset \n"
      ],
      "metadata": {
        "id": "PYJMzFQq4H6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = df.values\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=21\n",
        ")"
      ],
      "metadata": {
        "id": "inKZG_4M3SHo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize the rasampled dataset"
      ],
      "metadata": {
        "id": "rD8eXsLh4TvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "min_val = X_train.min().min()\n",
        "max_val = X_train.max().max()\n",
        "\n",
        "\n",
        "X_train = (X_train - min_val) / (max_val - min_val)\n",
        "X_test = (X_test - min_val) / (max_val - min_val)\n",
        "\n",
        "X_train = tf.cast(X_train, tf.float32)\n",
        "X_test = tf.cast(X_test, tf.float32)\n"
      ],
      "metadata": {
        "id": "NB2ou8C13SKY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))"
      ],
      "metadata": {
        "id": "v30ZzP5UOz1M"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOMFuDO1HZPO",
        "outputId": "7ce0a227-b2f3-41d9-cc32-d8a226a1fbcb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 140, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN LSTM MODEL"
      ],
      "metadata": {
        "id": "CuoYQHdfvUoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the LSTM Model  (one lstm layer with 64 cells no dropouts adam optimizer)\n"
      ],
      "metadata": {
        "id": "RPuz_tv-liml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(64, input_shape=(140,1)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10))\n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=Adam(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmnoHNhqbgAw",
        "outputId": "1bc28d7e-d37c-4296-df97-f00dc4ddc86f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 64)                16896     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64)               256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,802\n",
            "Trainable params: 17,674\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 27s 13ms/step - loss: 0.8585 - accuracy: 0.6831 - val_loss: 0.5837 - val_accuracy: 0.7658\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.5088 - accuracy: 0.7917 - val_loss: 0.3815 - val_accuracy: 0.8441\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3882 - accuracy: 0.8364 - val_loss: 0.3214 - val_accuracy: 0.8646\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3103 - accuracy: 0.8673 - val_loss: 0.2891 - val_accuracy: 0.8786\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.2794 - accuracy: 0.8798 - val_loss: 0.2516 - val_accuracy: 0.8871\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.2589 - accuracy: 0.8892 - val_loss: 0.2467 - val_accuracy: 0.8900\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.2399 - accuracy: 0.8955 - val_loss: 0.2066 - val_accuracy: 0.9115\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.2271 - accuracy: 0.9003 - val_loss: 0.2487 - val_accuracy: 0.8760\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2180 - accuracy: 0.9034 - val_loss: 0.2129 - val_accuracy: 0.9093\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2094 - accuracy: 0.9069 - val_loss: 0.2109 - val_accuracy: 0.9054\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 90.54%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 2s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.98      0.99      3978\n",
            "         2.0       0.81      0.78      0.79      4035\n",
            "         3.0       0.92      0.99      0.95      4042\n",
            "         4.0       0.80      0.78      0.79      3961\n",
            "         5.0       0.99      1.00      1.00      3984\n",
            "\n",
            "    accuracy                           0.91     20000\n",
            "   macro avg       0.90      0.91      0.90     20000\n",
            "weighted avg       0.90      0.91      0.90     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the LSTM Model  (one lstm layer with 64 cells with dropouts adam optimizer)\n"
      ],
      "metadata": {
        "id": "t6hjChGbgOHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(64, input_shape=(140,1)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(Dropout(0.2));\n",
        "model.add(layers.Dense(10))\n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=Adam(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "7gvFZ7OpgOHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49726c0-5fea-4da7-c5e2-ebf331c5c9f4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 64)                16896     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,802\n",
            "Trainable params: 17,674\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 13s 9ms/step - loss: 0.9878 - accuracy: 0.6421 - val_loss: 0.8576 - val_accuracy: 0.6812\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6635 - accuracy: 0.7415 - val_loss: 0.6112 - val_accuracy: 0.7400\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.5005 - accuracy: 0.7965 - val_loss: 0.4226 - val_accuracy: 0.8213\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.4026 - accuracy: 0.8328 - val_loss: 0.3020 - val_accuracy: 0.8739\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.3451 - accuracy: 0.8555 - val_loss: 0.2958 - val_accuracy: 0.8773\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.3130 - accuracy: 0.8672 - val_loss: 0.2521 - val_accuracy: 0.8799\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2851 - accuracy: 0.8780 - val_loss: 0.2671 - val_accuracy: 0.8891\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2780 - accuracy: 0.8803 - val_loss: 0.2490 - val_accuracy: 0.8943\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2547 - accuracy: 0.8891 - val_loss: 0.2301 - val_accuracy: 0.9066\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2462 - accuracy: 0.8931 - val_loss: 0.2800 - val_accuracy: 0.8751\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 87.51%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 3s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.98      0.98      0.98      3978\n",
            "         2.0       0.80      0.68      0.73      4035\n",
            "         3.0       0.96      0.93      0.94      4042\n",
            "         4.0       0.70      0.80      0.75      3961\n",
            "         5.0       0.94      1.00      0.97      3984\n",
            "\n",
            "    accuracy                           0.88     20000\n",
            "   macro avg       0.88      0.88      0.87     20000\n",
            "weighted avg       0.88      0.88      0.87     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the LSTM Model  (one lstm layer with 64 cells no dropouts sgd optimizer)\n"
      ],
      "metadata": {
        "id": "VM4zoQCXmFbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(64, input_shape=(140,1)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10))\n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=SGD(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "1zDnQhVAeqzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8efc480-e011-493b-bd79-fb306b14a901"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 64)                16896     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,802\n",
            "Trainable params: 17,674\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 1.8753 - accuracy: 0.3814 - val_loss: 1.6914 - val_accuracy: 0.4457\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 1.6177 - accuracy: 0.4574 - val_loss: 1.5421 - val_accuracy: 0.4618\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4897 - accuracy: 0.4738 - val_loss: 1.4300 - val_accuracy: 0.4929\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 1.3864 - accuracy: 0.5038 - val_loss: 1.3210 - val_accuracy: 0.5604\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2734 - accuracy: 0.5666 - val_loss: 1.1990 - val_accuracy: 0.6091\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1569 - accuracy: 0.5882 - val_loss: 1.1125 - val_accuracy: 0.5959\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0626 - accuracy: 0.6193 - val_loss: 1.0279 - val_accuracy: 0.6298\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0166 - accuracy: 0.6316 - val_loss: 1.0034 - val_accuracy: 0.6400\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.9859 - accuracy: 0.6378 - val_loss: 0.9702 - val_accuracy: 0.6375\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.9552 - accuracy: 0.6499 - val_loss: 0.9243 - val_accuracy: 0.6625\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 66.25%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 3s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.77      0.96      0.86      3978\n",
            "         2.0       0.63      0.84      0.72      4035\n",
            "         3.0       0.70      0.54      0.61      4042\n",
            "         4.0       0.53      0.47      0.50      3961\n",
            "         5.0       0.66      0.50      0.57      3984\n",
            "\n",
            "    accuracy                           0.66     20000\n",
            "   macro avg       0.66      0.66      0.65     20000\n",
            "weighted avg       0.66      0.66      0.65     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the LSTM Model  (one lstm layer with 64 cells with dropouts sgd optimizer)\n"
      ],
      "metadata": {
        "id": "m5dKbOrOgeHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(64, input_shape=(140,1)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(Dropout(0.2));\n",
        "model.add(layers.Dense(10))\n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=SGD(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "YZKjfeSageHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67898b8-f1b3-44b5-b95f-1fa3fdf9ca20"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 64)                16896     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,802\n",
            "Trainable params: 17,674\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 14s 9ms/step - loss: 1.9309 - accuracy: 0.3654 - val_loss: 1.6842 - val_accuracy: 0.4548\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 1.6307 - accuracy: 0.4500 - val_loss: 1.5330 - val_accuracy: 0.4649\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 1.5130 - accuracy: 0.4621 - val_loss: 1.4361 - val_accuracy: 0.4690\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4245 - accuracy: 0.4821 - val_loss: 1.3483 - val_accuracy: 0.4800\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3383 - accuracy: 0.5160 - val_loss: 1.2645 - val_accuracy: 0.5536\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 1.2478 - accuracy: 0.5509 - val_loss: 1.1611 - val_accuracy: 0.5936\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1410 - accuracy: 0.5930 - val_loss: 1.0534 - val_accuracy: 0.6212\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0776 - accuracy: 0.6152 - val_loss: 1.0202 - val_accuracy: 0.6273\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0438 - accuracy: 0.6265 - val_loss: 1.0448 - val_accuracy: 0.6433\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0178 - accuracy: 0.6341 - val_loss: 0.9553 - val_accuracy: 0.6524\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 65.24%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 2s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.80      0.95      0.87      3978\n",
            "         2.0       0.57      0.85      0.68      4035\n",
            "         3.0       0.68      0.54      0.60      4042\n",
            "         4.0       0.55      0.42      0.48      3961\n",
            "         5.0       0.66      0.50      0.57      3984\n",
            "\n",
            "    accuracy                           0.65     20000\n",
            "   macro avg       0.65      0.65      0.64     20000\n",
            "weighted avg       0.65      0.65      0.64     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the LSTM Model (two lstm layer with 64 cells no dropouts adam optimizer)\n"
      ],
      "metadata": {
        "id": "ks1Uvvvh53LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(64, return_sequences=True,input_shape=(140,1)))\n",
        "model.add(layers.LSTM(64,return_sequences=False))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10))\n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=Adam(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "6w2gTc_DfIkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081301d1-9c2a-4e62-f5c5-9c4e455705e4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 140, 64)           16896     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,826\n",
            "Trainable params: 50,698\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 20s 14ms/step - loss: 0.7188 - accuracy: 0.7326 - val_loss: 0.4245 - val_accuracy: 0.8232\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.3780 - accuracy: 0.8411 - val_loss: 0.3423 - val_accuracy: 0.8609\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.2741 - accuracy: 0.8830 - val_loss: 0.3129 - val_accuracy: 0.8664\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2356 - accuracy: 0.8975 - val_loss: 0.2643 - val_accuracy: 0.8956\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.2081 - accuracy: 0.9097 - val_loss: 0.2383 - val_accuracy: 0.8992\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.1937 - accuracy: 0.9161 - val_loss: 0.1528 - val_accuracy: 0.9318\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.1636 - accuracy: 0.9278 - val_loss: 0.1201 - val_accuracy: 0.9453\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.1473 - accuracy: 0.9357 - val_loss: 0.1100 - val_accuracy: 0.9482\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.1364 - accuracy: 0.9446 - val_loss: 0.1410 - val_accuracy: 0.9454\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.1055 - accuracy: 0.9581 - val_loss: 0.0780 - val_accuracy: 0.9706\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 97.06%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 4s 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      1.00      1.00      3978\n",
            "         2.0       0.95      0.91      0.93      4035\n",
            "         3.0       0.99      1.00      0.99      4042\n",
            "         4.0       0.93      0.95      0.94      3961\n",
            "         5.0       0.99      1.00      1.00      3984\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.97      0.97      0.97     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the LSTM Model (two lstm layer with 64 cells with dropouts adam optimizer)\n"
      ],
      "metadata": {
        "id": "Xr0wSz12gvmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(64, return_sequences=True,input_shape=(140,1)))\n",
        "model.add(layers.LSTM(64,return_sequences=False))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(Dropout(0.2));\n",
        "model.add(layers.Dense(10))\n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=Adam(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "LX0YjcBQgvme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b7803c-d327-49c3-fc10-9fcee02a1f1d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 140, 64)           16896     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,826\n",
            "Trainable params: 50,698\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 21s 14ms/step - loss: 0.8741 - accuracy: 0.6784 - val_loss: 0.6406 - val_accuracy: 0.7287\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4636 - accuracy: 0.8101 - val_loss: 0.3052 - val_accuracy: 0.8677\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.3192 - accuracy: 0.8655 - val_loss: 0.2867 - val_accuracy: 0.8881\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2781 - accuracy: 0.8823 - val_loss: 0.2128 - val_accuracy: 0.9026\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.2391 - accuracy: 0.8977 - val_loss: 0.1990 - val_accuracy: 0.9139\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.2297 - accuracy: 0.9022 - val_loss: 0.2974 - val_accuracy: 0.8783\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.2189 - accuracy: 0.9058 - val_loss: 0.1533 - val_accuracy: 0.9306\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.2246 - accuracy: 0.9068 - val_loss: 0.1713 - val_accuracy: 0.9218\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.1766 - accuracy: 0.9223 - val_loss: 0.1652 - val_accuracy: 0.9317\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.1605 - accuracy: 0.9319 - val_loss: 0.1151 - val_accuracy: 0.9510\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 95.10%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 4s 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.99      1.00      3978\n",
            "         2.0       0.93      0.83      0.87      4035\n",
            "         3.0       0.99      1.00      0.99      4042\n",
            "         4.0       0.85      0.94      0.89      3961\n",
            "         5.0       0.99      1.00      0.99      3984\n",
            "\n",
            "    accuracy                           0.95     20000\n",
            "   macro avg       0.95      0.95      0.95     20000\n",
            "weighted avg       0.95      0.95      0.95     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the LSTM Model (two lstm layer with 64 cells no dropouts sgd optimizer)\n"
      ],
      "metadata": {
        "id": "QfsDF9o953LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(64, return_sequences=True,input_shape=(140,1)))\n",
        "model.add(layers.LSTM(64,return_sequences=False))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10))\n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=SGD(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "JkZeeTO553LV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac22c34-37e8-4f71-fb9a-57d8f2b96ebd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 140, 64)           16896     \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,826\n",
            "Trainable params: 50,698\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 20s 14ms/step - loss: 1.9005 - accuracy: 0.3825 - val_loss: 1.7106 - val_accuracy: 0.4355\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.5703 - accuracy: 0.4909 - val_loss: 1.4674 - val_accuracy: 0.5136\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3964 - accuracy: 0.5399 - val_loss: 1.3211 - val_accuracy: 0.5690\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.2654 - accuracy: 0.5987 - val_loss: 1.2149 - val_accuracy: 0.6296\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.1870 - accuracy: 0.6197 - val_loss: 1.1506 - val_accuracy: 0.6276\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.1362 - accuracy: 0.6233 - val_loss: 1.1184 - val_accuracy: 0.6143\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.0665 - accuracy: 0.6268 - val_loss: 1.0071 - val_accuracy: 0.6237\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.9656 - accuracy: 0.6412 - val_loss: 0.9200 - val_accuracy: 0.6443\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.9227 - accuracy: 0.6460 - val_loss: 0.8969 - val_accuracy: 0.6425\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.8988 - accuracy: 0.6467 - val_loss: 0.8773 - val_accuracy: 0.6508\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 65.08%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 5s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.78      0.97      0.86      3978\n",
            "         2.0       0.64      0.83      0.73      4035\n",
            "         3.0       0.66      0.57      0.61      4042\n",
            "         4.0       0.53      0.47      0.49      3961\n",
            "         5.0       0.59      0.42      0.49      3984\n",
            "\n",
            "    accuracy                           0.65     20000\n",
            "   macro avg       0.64      0.65      0.64     20000\n",
            "weighted avg       0.64      0.65      0.64     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the LSTM Model (two lstm layer with 64 cells with dropouts sgd optimizer)\n"
      ],
      "metadata": {
        "id": "Vfhuk5mng0y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(64, return_sequences=True,input_shape=(140,1)))\n",
        "model.add(layers.LSTM(64,return_sequences=False))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(Dropout(0.2));\n",
        "model.add(layers.Dense(10))\n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=SGD(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "kQSPhJDog0y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884dee94-8270-4ab5-86e1-569ca3793085"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 140, 64)           16896     \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 64)                33024     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,826\n",
            "Trainable params: 50,698\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 21s 14ms/step - loss: 1.9719 - accuracy: 0.3475 - val_loss: 1.7724 - val_accuracy: 0.4025\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.6623 - accuracy: 0.4350 - val_loss: 1.5484 - val_accuracy: 0.4661\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.4823 - accuracy: 0.4868 - val_loss: 1.3806 - val_accuracy: 0.5197\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.3511 - accuracy: 0.5399 - val_loss: 1.2665 - val_accuracy: 0.6204\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 1.2404 - accuracy: 0.5962 - val_loss: 1.1661 - val_accuracy: 0.6243\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.1796 - accuracy: 0.6073 - val_loss: 1.1263 - val_accuracy: 0.6188\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.1454 - accuracy: 0.6112 - val_loss: 1.0949 - val_accuracy: 0.6274\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.1204 - accuracy: 0.6130 - val_loss: 1.0759 - val_accuracy: 0.6361\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.0985 - accuracy: 0.6147 - val_loss: 1.0575 - val_accuracy: 0.6315\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.0835 - accuracy: 0.6145 - val_loss: 1.0498 - val_accuracy: 0.6461\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 64.61%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 5s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.81      0.96      0.88      3978\n",
            "         2.0       0.56      0.75      0.64      4035\n",
            "         3.0       0.60      0.50      0.54      4042\n",
            "         4.0       0.61      0.36      0.45      3961\n",
            "         5.0       0.63      0.66      0.65      3984\n",
            "\n",
            "    accuracy                           0.65     20000\n",
            "   macro avg       0.64      0.65      0.63     20000\n",
            "weighted avg       0.64      0.65      0.63     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BIDIRECTIONAL LSTM"
      ],
      "metadata": {
        "id": "d1PB6dXJ4n6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam Optimizer"
      ],
      "metadata": {
        "id": "y0Zsfizj_bP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the BI-LSTM Model  \n"
      ],
      "metadata": {
        "id": "5z61hoUk43jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=X_train.shape\n",
        "model = keras.Sequential()\n",
        "model.add(Bidirectional(LSTM(64, input_shape=(140,1))))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10))\n",
        "model.build(input_shape) \n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=Adam(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "g2hoKv1p43jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a42610-4769-452a-ef39-53d9b2d3b6d8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (80000, 128)             33792     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (80000, 128)             512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (80000, 10)               1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,594\n",
            "Trainable params: 35,338\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 22s 15ms/step - loss: 0.7258 - accuracy: 0.7304 - val_loss: 0.6520 - val_accuracy: 0.7282\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.4371 - accuracy: 0.8222 - val_loss: 0.4115 - val_accuracy: 0.8101\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3210 - accuracy: 0.8661 - val_loss: 0.2749 - val_accuracy: 0.8938\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 0.2718 - accuracy: 0.8859 - val_loss: 0.2427 - val_accuracy: 0.8968\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.2467 - accuracy: 0.8933 - val_loss: 0.2159 - val_accuracy: 0.9122\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.2535 - accuracy: 0.8923 - val_loss: 0.2538 - val_accuracy: 0.8888\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2227 - accuracy: 0.9037 - val_loss: 0.2320 - val_accuracy: 0.8957\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.2074 - accuracy: 0.9085 - val_loss: 0.2486 - val_accuracy: 0.9089\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.2046 - accuracy: 0.9115 - val_loss: 0.1662 - val_accuracy: 0.9234\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.1880 - accuracy: 0.9180 - val_loss: 0.1788 - val_accuracy: 0.9222\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 92.22%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 4s 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.98      0.99      3978\n",
            "         2.0       0.87      0.80      0.83      4035\n",
            "         3.0       0.93      1.00      0.97      4042\n",
            "         4.0       0.82      0.83      0.83      3961\n",
            "         5.0       0.99      1.00      0.99      3984\n",
            "\n",
            "    accuracy                           0.92     20000\n",
            "   macro avg       0.92      0.92      0.92     20000\n",
            "weighted avg       0.92      0.92      0.92     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the BI-LSTM Model two lstm layers\n"
      ],
      "metadata": {
        "id": "0l5XXZ3p8T-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=X_train.shape\n",
        "model = keras.Sequential()\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True,input_shape=(140,1))))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False,input_shape=(140,1))))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10))\n",
        "model.build(input_shape) \n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=Adam(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "uB7YMIiW8T--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b47ff18-5cb6-4f5b-9fbc-d2de9f4e72d2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (80000, 140, 128)        33792     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (80000, 128)             98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (80000, 128)             512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (80000, 10)               1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,410\n",
            "Trainable params: 134,154\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 39s 26ms/step - loss: 0.6039 - accuracy: 0.7718 - val_loss: 0.3397 - val_accuracy: 0.8656\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.2778 - accuracy: 0.8804 - val_loss: 0.2030 - val_accuracy: 0.9112\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 0.2082 - accuracy: 0.9086 - val_loss: 0.1610 - val_accuracy: 0.9352\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 0.1632 - accuracy: 0.9297 - val_loss: 0.1733 - val_accuracy: 0.9251\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.1344 - accuracy: 0.9425 - val_loss: 0.0985 - val_accuracy: 0.9610\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.1169 - accuracy: 0.9521 - val_loss: 0.0853 - val_accuracy: 0.9643\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0947 - accuracy: 0.9634 - val_loss: 0.0580 - val_accuracy: 0.9798\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.0805 - accuracy: 0.9689 - val_loss: 0.0610 - val_accuracy: 0.9710\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.0783 - accuracy: 0.9715 - val_loss: 0.0499 - val_accuracy: 0.9829\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0533 - accuracy: 0.9813 - val_loss: 0.0816 - val_accuracy: 0.9669\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 96.69%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 8s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      1.00      1.00      3978\n",
            "         2.0       0.90      0.95      0.92      4035\n",
            "         3.0       1.00      1.00      1.00      4042\n",
            "         4.0       0.95      0.89      0.92      3961\n",
            "         5.0       1.00      1.00      1.00      3984\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.97      0.97      0.97     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Construct the BI-LSTM Model two lstm layers with dropout"
      ],
      "metadata": {
        "id": "ka-gtL3y88cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=X_train.shape\n",
        "model = keras.Sequential()\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True,input_shape=(140,1))))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False,input_shape=(140,1))))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(Dropout(0.2));\n",
        "model.add(layers.Dense(10))\n",
        "model.build(input_shape) \n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=Adam(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "JeWto8PO8zlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6fd1ef-f650-4af2-dd6b-cad21d671182"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_3 (Bidirectio  (80000, 140, 128)        33792     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (80000, 128)             98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (80000, 128)             512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (80000, 128)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (80000, 10)               1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,410\n",
            "Trainable params: 134,154\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 39s 26ms/step - loss: 0.7324 - accuracy: 0.7278 - val_loss: 0.4592 - val_accuracy: 0.8166\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 0.3748 - accuracy: 0.8398 - val_loss: 0.2743 - val_accuracy: 0.8810\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.2597 - accuracy: 0.8864 - val_loss: 0.1972 - val_accuracy: 0.9079\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.2177 - accuracy: 0.9031 - val_loss: 0.1965 - val_accuracy: 0.9168\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.1822 - accuracy: 0.9194 - val_loss: 0.1508 - val_accuracy: 0.9336\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.1553 - accuracy: 0.9324 - val_loss: 0.1424 - val_accuracy: 0.9342\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.1337 - accuracy: 0.9447 - val_loss: 0.0955 - val_accuracy: 0.9575\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.1267 - accuracy: 0.9515 - val_loss: 0.0935 - val_accuracy: 0.9586\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.1023 - accuracy: 0.9596 - val_loss: 0.0768 - val_accuracy: 0.9722\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0864 - accuracy: 0.9666 - val_loss: 0.0600 - val_accuracy: 0.9809\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 98.09%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 8s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      1.00      1.00      3978\n",
            "         2.0       0.95      0.95      0.95      4035\n",
            "         3.0       0.99      1.00      1.00      4042\n",
            "         4.0       0.96      0.95      0.96      3961\n",
            "         5.0       1.00      1.00      1.00      3984\n",
            "\n",
            "    accuracy                           0.98     20000\n",
            "   macro avg       0.98      0.98      0.98     20000\n",
            "weighted avg       0.98      0.98      0.98     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD Optimizer"
      ],
      "metadata": {
        "id": "xbfU4-qh_d5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the BI-LSTM Model  \n"
      ],
      "metadata": {
        "id": "ag9seGa3_mw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=X_train.shape\n",
        "model = keras.Sequential()\n",
        "model.add(Bidirectional(LSTM(64, input_shape=(140,1))))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10))\n",
        "model.build(input_shape) \n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=SGD(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "dsWydJmG_mw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83bd383-baaf-486e-d3e8-559638822f39"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_5 (Bidirectio  (80000, 128)             33792     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (80000, 128)             512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_11 (Dense)            (80000, 10)               1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,594\n",
            "Trainable params: 35,338\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 21s 14ms/step - loss: 1.8521 - accuracy: 0.3963 - val_loss: 1.5939 - val_accuracy: 0.4947\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.4902 - accuracy: 0.4951 - val_loss: 1.4059 - val_accuracy: 0.5045\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3475 - accuracy: 0.5197 - val_loss: 1.2847 - val_accuracy: 0.5318\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 1.2473 - accuracy: 0.5507 - val_loss: 1.1942 - val_accuracy: 0.5687\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.1627 - accuracy: 0.5812 - val_loss: 1.1147 - val_accuracy: 0.5929\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.0848 - accuracy: 0.6061 - val_loss: 1.0452 - val_accuracy: 0.6277\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 1.0233 - accuracy: 0.6260 - val_loss: 0.9943 - val_accuracy: 0.6251\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.9759 - accuracy: 0.6410 - val_loss: 0.9493 - val_accuracy: 0.6410\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9412 - accuracy: 0.6568 - val_loss: 0.9206 - val_accuracy: 0.6716\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.9152 - accuracy: 0.6657 - val_loss: 0.9036 - val_accuracy: 0.6836\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 68.36%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 4s 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.86      0.97      0.91      3978\n",
            "         2.0       0.59      0.78      0.68      4035\n",
            "         3.0       0.75      0.60      0.67      4042\n",
            "         4.0       0.57      0.49      0.53      3961\n",
            "         5.0       0.64      0.58      0.61      3984\n",
            "\n",
            "    accuracy                           0.68     20000\n",
            "   macro avg       0.68      0.68      0.68     20000\n",
            "weighted avg       0.68      0.68      0.68     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5wIEVbhN_oms"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the BI-LSTM Model two lstm layers\n"
      ],
      "metadata": {
        "id": "4y067f48_rkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=X_train.shape\n",
        "model = keras.Sequential()\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True,input_shape=(140,1))))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False,input_shape=(140,1))))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10))\n",
        "model.build(input_shape) \n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=SGD(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")"
      ],
      "metadata": {
        "id": "0rfQiOtb_rkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70338b2-7fc1-4710-c6d0-14ead3a22b72"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirectio  (80000, 140, 128)        33792     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (80000, 128)             98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (80000, 128)             512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            (80000, 10)               1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,410\n",
            "Trainable params: 134,154\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 40s 27ms/step - loss: 1.8390 - accuracy: 0.4347 - val_loss: 1.5854 - val_accuracy: 0.5067\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 1.4516 - accuracy: 0.5344 - val_loss: 1.3375 - val_accuracy: 0.5823\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.2666 - accuracy: 0.5809 - val_loss: 1.2167 - val_accuracy: 0.6028\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.1626 - accuracy: 0.5970 - val_loss: 1.1281 - val_accuracy: 0.6105\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 1.0812 - accuracy: 0.6149 - val_loss: 1.0396 - val_accuracy: 0.6160\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.0080 - accuracy: 0.6416 - val_loss: 0.9815 - val_accuracy: 0.6548\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 0.9571 - accuracy: 0.6555 - val_loss: 0.9327 - val_accuracy: 0.6546\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 0.9171 - accuracy: 0.6622 - val_loss: 0.8906 - val_accuracy: 0.6694\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 0.8815 - accuracy: 0.6742 - val_loss: 0.8650 - val_accuracy: 0.6708\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.8544 - accuracy: 0.6850 - val_loss: 0.8348 - val_accuracy: 0.6859\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 68.59%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 8s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.87      0.95      0.91      3978\n",
            "         2.0       0.58      0.79      0.67      4035\n",
            "         3.0       0.77      0.59      0.67      4042\n",
            "         4.0       0.54      0.51      0.52      3961\n",
            "         5.0       0.70      0.59      0.64      3984\n",
            "\n",
            "    accuracy                           0.69     20000\n",
            "   macro avg       0.69      0.69      0.68     20000\n",
            "weighted avg       0.69      0.69      0.68     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Construct the BI-LSTM Model two lstm layers with dropout"
      ],
      "metadata": {
        "id": "xbHmVu9F_wHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=X_train.shape\n",
        "model = keras.Sequential()\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True,input_shape=(140,1))))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False,input_shape=(140,1))))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(Dropout(0.2));\n",
        "model.add(layers.Dense(10))\n",
        "model.build(input_shape) \n",
        "print(model.summary())\n",
        "print(\"==============================================================================\")\n",
        "print(\"==============================================================================\")\n",
        "model.compile(\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=SGD(learning_rate=0.001),\n",
        "  metrics=[\"accuracy\"],\n",
        ")\t\n",
        "\n",
        "\n",
        "hist = model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=10\n",
        ")\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n",
        "\n",
        "predictions=model.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"===============================================================================\")\n",
        "print(\"===============================================================================\")\n",
        "\n"
      ],
      "metadata": {
        "id": "HhkilOMk_wHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d98e112-e958-473f-977d-a1acd5dc117a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_8 (Bidirectio  (80000, 140, 128)        33792     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (80000, 128)             98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (80000, 128)             512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (80000, 128)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (80000, 10)               1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,410\n",
            "Trainable params: 134,154\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================================================================\n",
            "==============================================================================\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 41s 27ms/step - loss: 1.8521 - accuracy: 0.4338 - val_loss: 1.6116 - val_accuracy: 0.5243\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.5224 - accuracy: 0.5114 - val_loss: 1.3999 - val_accuracy: 0.5390\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.3502 - accuracy: 0.5453 - val_loss: 1.2555 - val_accuracy: 0.5730\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.2358 - accuracy: 0.5696 - val_loss: 1.1657 - val_accuracy: 0.5940\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 1.1570 - accuracy: 0.5901 - val_loss: 1.1133 - val_accuracy: 0.5982\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 1.0882 - accuracy: 0.6073 - val_loss: 1.0350 - val_accuracy: 0.6246\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.0176 - accuracy: 0.6241 - val_loss: 0.9541 - val_accuracy: 0.6467\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.9645 - accuracy: 0.6386 - val_loss: 0.9230 - val_accuracy: 0.6639\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9328 - accuracy: 0.6496 - val_loss: 0.8812 - val_accuracy: 0.6731\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9075 - accuracy: 0.6590 - val_loss: 0.8614 - val_accuracy: 0.6832\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "Final Accuracy: 68.32%\n",
            "===============================================================================\n",
            "===============================================================================\n",
            "625/625 [==============================] - 8s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.81      0.93      0.86      3978\n",
            "         2.0       0.63      0.82      0.71      4035\n",
            "         3.0       0.70      0.67      0.69      4042\n",
            "         4.0       0.58      0.48      0.53      3961\n",
            "         5.0       0.67      0.51      0.58      3984\n",
            "\n",
            "    accuracy                           0.68     20000\n",
            "   macro avg       0.68      0.68      0.67     20000\n",
            "weighted avg       0.68      0.68      0.67     20000\n",
            "\n",
            "===============================================================================\n",
            "===============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper parameter tuning Using Keras Tuner"
      ],
      "metadata": {
        "id": "Nvo7n1AonilC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "0NKylnBY4bDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import sigmoid\n",
        "from keras.layers.serialization import activation\n",
        "def LstmModel(hp):\n",
        "  input_shape = (140, 1)\n",
        "  model = keras.Sequential()\n",
        "  for i in range(hp.Int('layers',2,6)):\n",
        "    model.add(layers.LSTM(units = hp.Int('units_' + str(i), 64,130,step = 20),\n",
        "                          input_shape=input_shape,\n",
        "                          activation=hp.Choice('act_' + str(i),['relu', 'sigmoid']),return_sequences=True))\n",
        "  model.add(layers.LSTM(units= 64, input_shape=input_shape,\n",
        "                          activation= 'sigmoid',return_sequences=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(Dropout(hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "  model.add(layers.Dense(units=10,activation = 'softmax'))\n",
        "  model.compile(\n",
        "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=Adam(hp.Choice('learning_rate',\n",
        "                             values = [1e-2,1e-4])),\n",
        "    metrics=[\"accuracy\"],\n",
        "  )\t\n",
        "  return model"
      ],
      "metadata": {
        "id": "wjLzvAVgnp5i"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    LstmModel,\n",
        "    objective = 'val_accuracy',\n",
        "    max_trials = 5,\n",
        "    executions_per_trial = 1,\n",
        "    directory = 'my_dir',\n",
        "    project_name = 'Deep Learning Module :D'\n",
        ")"
      ],
      "metadata": {
        "id": "NUA5exQGp7Z7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e2231d-5fe6-4a2e-c176-50c4ea91f6e7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "Wh85CJ7Dqipj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06525ca8-90af-4851-ba38-d72df2cc6151"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 7\n",
            "layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 6, 'step': 1, 'sampling': 'linear'}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 130, 'step': 20, 'sampling': 'linear'}\n",
            "act_0 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 130, 'step': 20, 'sampling': 'linear'}\n",
            "act_1 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
            "dropout_rate (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.0001], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n"
      ],
      "metadata": {
        "id": "oE_Xq4Fdu-Y9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train,y_train, batch_size=128,epochs =1, validation_data =(X_test, y_test), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "BqfbNcxkqrBz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "4d88ccd0-624e-436f-a370-dec5c0d2cd48"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #2\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "2                 |3                 |layers\n",
            "84                |84                |units_0\n",
            "sigmoid           |sigmoid           |act_0\n",
            "124               |124               |units_1\n",
            "relu              |sigmoid           |act_1\n",
            "0.1               |0.2               |dropout_rate\n",
            "0.01              |0.01              |learning_rate\n",
            "104               |64                |units_2\n",
            "sigmoid           |relu              |act_2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  6/625 [..............................] - ETA: 12:14 - loss: nan - accuracy: 0.1380"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-fef026ee5b5e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    216\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "538XTlIQq7_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BIDIRECTIONAL LSTM"
      ],
      "metadata": {
        "id": "r67BmIwhkf17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BiLstmModel(hp):\n",
        "  input_shape = (140, 1)\n",
        "  model = keras.Sequential()\n",
        "  for i in range(hp.Int('layers',2,6)):\n",
        "    model.add(layers.Bidirectional(LSTM(units = hp.Int('units_' + str(i), 50,100,step = 10),\n",
        "                          input_shape=input_shape,\n",
        "                          activation=hp.Choice('act_' + str(i),['relu', 'sigmoid']),return_sequences=True)))\n",
        "  model.add(layers.Bidirectional(LSTM(units = hp.Int('units_' + str(i), 50,100,step = 10),\n",
        "                          input_shape=input_shape,\n",
        "                          activation=hp.Choice('act_' + str(i),['relu', 'sigmoid']),return_sequences=False)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(Dropout(hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "  model.add(layers.Dense(units=10,activation = 'softmax'))\n",
        "  model.compile(\n",
        "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=Adam(hp.Choice('learning_rate',\n",
        "                             values = [1e-2,1e-4])),\n",
        "    metrics=[\"accuracy\"],\n",
        "  )\t\n",
        "  return model"
      ],
      "metadata": {
        "id": "9qX8QtcHkjoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    BiLstmModel,\n",
        "    objective = 'val_accuracy',\n",
        "    max_trials = 5,\n",
        "    executions_per_trial = 3,\n",
        "    directory = 'my_dir',\n",
        "    project_name = 'Deep Learning Module :D'\n",
        ")"
      ],
      "metadata": {
        "id": "pAX3a50FyE77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "WEiycljHyE1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train,y_train, epochs =10, validation_data =(X_test, y_test))"
      ],
      "metadata": {
        "id": "637Cwhv2yEyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "FN2QmqP7yEli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}